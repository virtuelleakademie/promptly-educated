[
  {
    "objectID": "slides/workshop-global-management.html#what-is-artifical-intelligence",
    "href": "slides/workshop-global-management.html#what-is-artifical-intelligence",
    "title": "Workshop: Global Management",
    "section": "What is Artifical Intelligence?",
    "text": "What is Artifical Intelligence?\n\n\n\n\nA branch of computer science that aims to create machines that can perform tasks that typically require human intelligence."
  },
  {
    "objectID": "slides/workshop-global-management.html#what-is-a-large-language-model",
    "href": "slides/workshop-global-management.html#what-is-a-large-language-model",
    "title": "Workshop: Global Management",
    "section": "What is a Large Language Model?",
    "text": "What is a Large Language Model?\n\n\n\n\nAn LLM is a type of generative AI model that is trained to predict the next word following the input (prompt)."
  },
  {
    "objectID": "slides/workshop-global-management.html#how-to-train-a-language-model",
    "href": "slides/workshop-global-management.html#how-to-train-a-language-model",
    "title": "Workshop: Global Management",
    "section": "How to train a language model",
    "text": "How to train a language model\n\nAn LLM learns to predict the next word in a sequence, given the previous words: \\[ P(word | context) \\]\nThink of as “fancy autocomplete” (but very very powerful and sopisticated)"
  },
  {
    "objectID": "slides/workshop-global-management.html#how-does-an-llm-generate-text",
    "href": "slides/workshop-global-management.html#how-does-an-llm-generate-text",
    "title": "Workshop: Global Management",
    "section": "How does an LLM generate text?",
    "text": "How does an LLM generate text?"
  },
  {
    "objectID": "slides/workshop-global-management.html#sampling",
    "href": "slides/workshop-global-management.html#sampling",
    "title": "Workshop: Global Management",
    "section": "Sampling",
    "text": "Sampling"
  },
  {
    "objectID": "slides/workshop-global-management.html#auto-regressive-generation",
    "href": "slides/workshop-global-management.html#auto-regressive-generation",
    "title": "Workshop: Global Management",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation\nText is generated one word at a time (actually tokens, not words).\n\n\n\n\n\n Generated text depends on the generative model and the context.\n Every word (token) is given an equal amount time (computation per token is constant)."
  },
  {
    "objectID": "slides/workshop-global-management.html#auto-regressive-generation-1",
    "href": "slides/workshop-global-management.html#auto-regressive-generation-1",
    "title": "Workshop: Global Management",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation"
  },
  {
    "objectID": "slides/workshop-global-management.html#foundation-models",
    "href": "slides/workshop-global-management.html#foundation-models",
    "title": "Workshop: Global Management",
    "section": "Foundation models",
    "text": "Foundation models\nA foundation model, or large language model (LLM):\n\nis a type of machine learning model that is trained to predict the next word following the input (prompt).\nis trained “simply” to predict the next word following a sequence of words.\ndoes not necessarily produce human-like conversations.\n\n\n\n\n: What is the capital of France?\n: What is the capital of Germany? What is the capital of Italy? . .."
  },
  {
    "objectID": "slides/workshop-global-management.html#training-process",
    "href": "slides/workshop-global-management.html#training-process",
    "title": "Workshop: Global Management",
    "section": "Training process",
    "text": "Training process\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/workshop-global-management.html#assistant-models",
    "href": "slides/workshop-global-management.html#assistant-models",
    "title": "Workshop: Global Management",
    "section": "Assistant models",
    "text": "Assistant models\nTrained (fine-tuned) to have conversations: turn-taking, question answering, not being rude/sexist/racist.\n\n\n\n\n\n\nFoundation model has learned to predict all kinds of text, including both desirable and undesirable text.\nFine-tuning narrows down the space of all possible output to only desirable, human-like dialogue.\nModel is aligned with the values of the fine-tuner."
  },
  {
    "objectID": "slides/workshop-global-management.html#how-do-chatbots-work",
    "href": "slides/workshop-global-management.html#how-do-chatbots-work",
    "title": "Workshop: Global Management",
    "section": "How do Chatbots work?",
    "text": "How do Chatbots work?\n\n\nDesigned to present the illusion of a conversation between two entities."
  },
  {
    "objectID": "slides/workshop-global-management.html#how-do-chatbots-actually-work",
    "href": "slides/workshop-global-management.html#how-do-chatbots-actually-work",
    "title": "Workshop: Global Management",
    "section": "How do chatbots actually work?",
    "text": "How do chatbots actually work?"
  },
  {
    "objectID": "slides/workshop-global-management.html#an-assistant-model-is-a-conversation-simulator",
    "href": "slides/workshop-global-management.html#an-assistant-model-is-a-conversation-simulator",
    "title": "Workshop: Global Management",
    "section": "An assistant model is a conversation simulator",
    "text": "An assistant model is a conversation simulator\n\n\n\n\n\nAn assistant is trained to respond to user prompts in a human-like way.\nSimulates possible human conversations.\nHas no intentions. It is not an entity with its own goals.\nDoes not have a “personality” or “character” in the traditional sense. It can be thought of as a role-playing simulator.\nHas no concept of “truth” or “lying”. The model is not trying to deceive the user, it is simply trying to respond in a human-like way."
  },
  {
    "objectID": "slides/workshop-global-management.html#capabilities-and-limitations",
    "href": "slides/workshop-global-management.html#capabilities-and-limitations",
    "title": "Workshop: Global Management",
    "section": "Capabilities and limitations",
    "text": "Capabilities and limitations\n\n\nWhat are LLMs good at?\n\nFixing grammar, bad writing, etc.\nRephrasing\nAnalyzing texts\nWriting computer code\nAnswering questions about a knowledge base\nTranslating languages\nCreating structured output\nFactual output with external documents or web search\n\n\nLimitations\n\nThey make stuff up (hallucinate)\nThey learn biases from the training data\nWeird vocabulary, e.g. delve\n(Chatbots have privacy issues)"
  },
  {
    "objectID": "slides/workshop-global-management.html#hallucination",
    "href": "slides/workshop-global-management.html#hallucination",
    "title": "Workshop: Global Management",
    "section": "Hallucination",
    "text": "Hallucination\n\n\n\n\n\nLLMs can generate text that is not true, or not based on any real-world knowledge.\nThis is known as “hallucination”. A better term would be “confabulation”."
  },
  {
    "objectID": "slides/workshop-global-management.html#can-an-llm-tell-the-truth",
    "href": "slides/workshop-global-management.html#can-an-llm-tell-the-truth",
    "title": "Workshop: Global Management",
    "section": "Can an LLM tell the truth?",
    "text": "Can an LLM tell the truth?\n\nHow would you know if an LLM is able to give you factual information?\nHow would you test this?\n\n\n\n\n: What is the capital of Uzbekistan?\n: Tashkent\n\n\n\nIt looks like the LLM knows the capital of Uzbekistan1.\nWhat it is actually doing is responding with the most likely sequence following the question."
  },
  {
    "objectID": "slides/workshop-global-management.html#knowledge-base",
    "href": "slides/workshop-global-management.html#knowledge-base",
    "title": "Workshop: Global Management",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\nA knowledge base is a collection of facts about the world.\n\nYou can ask (retrieve) and tell (store) facts.\n\nAn LLM is not a knowledge base.\n\nLLMs generate text based on on how probable the next word is given the context, not based on stored facts."
  },
  {
    "objectID": "slides/workshop-global-management.html#biases",
    "href": "slides/workshop-global-management.html#biases",
    "title": "Workshop: Global Management",
    "section": "Biases",
    "text": "Biases\n\n\n\n\n\n\n\n\nBiases in LLMs\nSource\nExamples\n\n\n\n\nTraining data bias\nText from internet, books, articles.\nStereotypes reflecting gender, race, religion.\n\n\nRepresentation bias\nUnderrepresented groups/perspectives in data.\nLess accurate responses for minority cultures.\n\n\nAlgorithmic bias\nTraining and fine-tuning algorithms.\nOptimizations for fluency and coherence may lead to preference for dominant cultural narratives.\n\n\nUser interaction bias\nAdaptation based on user interactions.\nIncreased biased or harmful content generation."
  },
  {
    "objectID": "slides/workshop-global-management.html#privacy-concerns",
    "href": "slides/workshop-global-management.html#privacy-concerns",
    "title": "Workshop: Global Management",
    "section": "Privacy concerns",
    "text": "Privacy concerns\n\n\n\n\n\n\n\n\nPrivacy Concerns\nIssue\nExamples\n\n\n\n\nData memorization\nMemorizing sensitive information.\nReproducing phone numbers, addresses.\n\n\nTraining data leakage\nUnauthorized dissemination of confidential data.\nSummarizing proprietary documents.\n\n\nUser query logging\nStoring sensitive user interactions.\nExposing private queries if data is mishandled.\n\n\nQueries used for training\nUser queries may be used for further training.\nPersonal data in queries could be inadvertently included in training data."
  },
  {
    "objectID": "slides/workshop-global-management.html#prompting",
    "href": "slides/workshop-global-management.html#prompting",
    "title": "Workshop: Global Management",
    "section": "Prompting",
    "text": "Prompting"
  },
  {
    "objectID": "slides/workshop-global-management.html#what-is-a-prompt",
    "href": "slides/workshop-global-management.html#what-is-a-prompt",
    "title": "Workshop: Global Management",
    "section": "What is a prompt?",
    "text": "What is a prompt?\n\nAn LLM’s task is to complete text.\nA prompt is a piece of text (instruction) that is given to a language model to complete.\n\n\n\n\nPROMPT : Write a haiku about a workshop on large language models.\nASSISTANT : Whispers of circuits,\nKnowledge blooms in bytes and bits,\nModel learns and fits.\n\n\n\n\nThe response is generated as continuation of, and conditioned on, the prompt.\n\n\nMore technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt."
  },
  {
    "objectID": "slides/workshop-global-management.html#prompt-engineering",
    "href": "slides/workshop-global-management.html#prompt-engineering",
    "title": "Workshop: Global Management",
    "section": "Prompt engineering",
    "text": "Prompt engineering\n\n\n\n\n\nLLMs learn to do things they were not explicitly trained to do: translation, reasoning, etc. \nOften, these capabilities need to be “unlocked” by the right prompt. \n\n\n\nBut what is the right prompt?\nThe answer is very similar to what you would tell a human dialogue partner/assistant.\nYou can increase the probability of getting the desired output by providing context and examples."
  },
  {
    "objectID": "slides/workshop-global-management.html#basics-of-prompting",
    "href": "slides/workshop-global-management.html#basics-of-prompting",
    "title": "Workshop: Global Management",
    "section": "Basics of prompting",
    "text": "Basics of prompting\nOpenAI give a set of strategies for using their models effectively:\n Prompt engineering\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving the LLM ‘time to think’\nusing external tools"
  },
  {
    "objectID": "slides/workshop-global-management.html#writing-clear-instructions",
    "href": "slides/workshop-global-management.html#writing-clear-instructions",
    "title": "Workshop: Global Management",
    "section": "Writing clear instructions",
    "text": "Writing clear instructions\n\n\n\nInstructions should be clear and unambiguous.\nThink of an LLM as a role-playing conversation simulator: Indicate which role the model (persona) should adopt.\n\n\n\n\n\n\nInclude details in your query to get more relevant answers\nAsk the model to adopt a persona\nUse delimiters to clearly indicate distinct parts of the input\nSpecify the steps required to complete a task\nProvide examples\nSpecify the desired length of the output"
  },
  {
    "objectID": "slides/workshop-global-management.html#adopt-a-persona-role",
    "href": "slides/workshop-global-management.html#adopt-a-persona-role",
    "title": "Workshop: Global Management",
    "section": "Adopt a persona (role)",
    "text": "Adopt a persona (role)\n\n\n\n: You are an expert on learning techniques. Explain the concept of ‘flipped classroom’ in one paragraph.\n\n\n\n\n\n\n: You are an expert financial derivatives. Explain the concept of ‘flipped classroom’ in one paragraph."
  },
  {
    "objectID": "slides/workshop-global-management.html#provide-reference-texts",
    "href": "slides/workshop-global-management.html#provide-reference-texts",
    "title": "Workshop: Global Management",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\nProvide a model with trusted and relevant information.\nThen instruct the model to use the provided information to compose its answer.\n\n Instruct the model to answer using a reference text\n\n\n\nThis can be extended to retrieval-augmented generation (RAG). First create a database of documents, then retrieve the most relevant documents, based on a user’s query. These are then included in the prompt to the model. The model is instructed to use the information in the documents to compose its answer."
  },
  {
    "objectID": "slides/workshop-global-management.html#create-structured-output",
    "href": "slides/workshop-global-management.html#create-structured-output",
    "title": "Workshop: Global Management",
    "section": "Create structured output",
    "text": "Create structured output\n\nExplanation: Instruct the model to generate structured output.\nE.g. provide a table, a list, a diagram, etc.\nUse delimiters to indicate distinct parts of the input.\nExample: Extract information from a text and present it in a table."
  },
  {
    "objectID": "slides/workshop-global-management.html#structured-prompting-techniques",
    "href": "slides/workshop-global-management.html#structured-prompting-techniques",
    "title": "Workshop: Global Management",
    "section": "Structured prompting techniques",
    "text": "Structured prompting techniques\n\nIn-Context Learning: Provide examples within the prompt.\nThought Generation: Instruct the model to think step-by-step.\nDecomposition Techniques: Break down tasks into subtasks.\n\n(Schulhoff et al. 2024)"
  },
  {
    "objectID": "slides/workshop-global-management.html#in-context-learning",
    "href": "slides/workshop-global-management.html#in-context-learning",
    "title": "Workshop: Global Management",
    "section": "In-Context learning",
    "text": "In-Context learning\n\nExplanation: Providing examples or context within the prompt itself.\nFew-shot prompting: Give a few examples.\n\nExample: Translate the following sentences:\n\nEnglish: ‘What time is it?’ -&gt; French: ‘Quelle heure est-il?’\nEnglish: ‘Where is the library?’ -&gt; French:\n\n\nZero-shot prompting: No examples, relies on pre-trained knowledge.\n\nExample: Translate the following sentence…"
  },
  {
    "objectID": "slides/workshop-global-management.html#thought-generation",
    "href": "slides/workshop-global-management.html#thought-generation",
    "title": "Workshop: Global Management",
    "section": "Thought generation",
    "text": "Thought generation\n\nExplanation: Encourages the model to show its reasoning process.\nChain-of-Thought (CoT) prompting: encourages the LLM to “explain” its intermediate reasoning steps.\nCan often be induced by simply instructing the model to think step-by-step or Take a deep breath and work on this problem step-by-step (Yang et al. 2023)."
  },
  {
    "objectID": "slides/workshop-global-management.html#chain-of-thought-example",
    "href": "slides/workshop-global-management.html#chain-of-thought-example",
    "title": "Workshop: Global Management",
    "section": "Chain-of-Thought example",
    "text": "Chain-of-Thought example\nInstead of this:\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Yes or no?\n\n\n\nDo this:\n\n\n\n: Is this statement correct? The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\nReason through the problem step-by-step. Start by identifying the odd numbers. Next, add them up. Finally, determine if the sum is even or odd. Write down your reasoning steps in a numbered list.\n\n\n\n\nWhy does this work?"
  },
  {
    "objectID": "slides/workshop-global-management.html#decomposition-techniques",
    "href": "slides/workshop-global-management.html#decomposition-techniques",
    "title": "Workshop: Global Management",
    "section": "Decomposition techniques",
    "text": "Decomposition techniques\n\nExplanation: Force the LLM to break down complex tasks into manageable subtasks.\nLeast-to-Most Prompting: Start simple, increase complexity.\n\nExample: List items, calculate cost…\n\nPlan-and-Solve Prompting: Separate planning and execution phases.\n\nExample: Understand the problem, devise a plan…"
  },
  {
    "objectID": "slides/workshop-global-management.html#hands-on-practice-prompting",
    "href": "slides/workshop-global-management.html#hands-on-practice-prompting",
    "title": "Workshop: Global Management",
    "section": "Hands-on practice: Prompting",
    "text": "Hands-on practice: Prompting\n Open this activity.\n\nPractice writing prompts for different tasks ( 20 minutes).\nWrite an essay using an LLM, and then critique someone else’s essay ( 30 minutes).\n\n  If you need further help with prompting techniques, see these websites:\n\n Learn prompting\n Prompting guide\n OpenAI cookbook"
  },
  {
    "objectID": "slides/workshop-global-management.html#chatgpt-edu",
    "href": "slides/workshop-global-management.html#chatgpt-edu",
    "title": "Workshop: Global Management",
    "section": "ChatGPT Edu",
    "text": "ChatGPT Edu\n\n\n \n\n\n\n\nAccess to GPT-4o, excelling in text interpretation, coding, and mathematics\nData analytics, web browsing, and document summarization\nBuild GPTs, custom versions of ChatGPT, and share them within university workspaces\nSignificantly higher message limits than the free version of ChatGPT\nImproved language capabilities across quality and speed, with over 50 languages supported\nRobust security, data privacy, and administrative controls\nConversations and data are not used to train OpenAI models"
  },
  {
    "objectID": "slides/workshop-global-management.html#gpts",
    "href": "slides/workshop-global-management.html#gpts",
    "title": "Workshop: Global Management",
    "section": "GPTs",
    "text": "GPTs"
  },
  {
    "objectID": "slides/workshop-global-management.html#hands-on-practice-gpts",
    "href": "slides/workshop-global-management.html#hands-on-practice-gpts",
    "title": "Workshop: Global Management",
    "section": "Hands-on practice: GPTs",
    "text": "Hands-on practice: GPTs\n\nTry out custom GPTs from various categories in the GPT store.\nDiscuss with your neighbour\n\nDid you discover any useful GPTs?\nWhat are the benefits and limitations of using GPTs in the classroom?"
  },
  {
    "objectID": "slides/workshop-global-management.html#extended-cognition",
    "href": "slides/workshop-global-management.html#extended-cognition",
    "title": "Workshop: Global Management",
    "section": "Extended cognition",
    "text": "Extended cognition\n\n\n\nAccording to Clark and Chalmers (1998), cognitive processes may extend to external objects.\nKrakauer (2016) distinguishes between complementary and competitive cognitive artifacts.\n\nComplementary: numbers, abacus\nCompetetive: calculator, GPS\n\nWhat kind of artefact will AI turn out to be?"
  },
  {
    "objectID": "slides/workshop-global-management.html#deskilling-vs.-upskilling",
    "href": "slides/workshop-global-management.html#deskilling-vs.-upskilling",
    "title": "Workshop: Global Management",
    "section": "Deskilling vs. upskilling",
    "text": "Deskilling vs. upskilling"
  },
  {
    "objectID": "slides/workshop-global-management.html#writing-tasks-in-the-ai-era",
    "href": "slides/workshop-global-management.html#writing-tasks-in-the-ai-era",
    "title": "Workshop: Global Management",
    "section": "Writing tasks in the AI era",
    "text": "Writing tasks in the AI era\n\nWriting is a core skill: critical thinking, persuasion, argumentation, understanding.\nText creation is secondary in learning: focus is on underlying skills.\nLearning objectives: Benefits of writing tasks should be clearly and convincingly conveyed.\nStudents should be equipped for effective (controlled) use of AI."
  },
  {
    "objectID": "slides/workshop-global-management.html#ai-can-do-my-homework",
    "href": "slides/workshop-global-management.html#ai-can-do-my-homework",
    "title": "Workshop: Global Management",
    "section": "AI can do my homework",
    "text": "AI can do my homework\n\nWe can think of this as cheating.\nMore useful: cheating means bypassing useful cognition and therefore missing out on learning.\nCheating an ethics problem.\nBypassing cognition is a learning problem.\nNot a new problem: books, encyclopedias, calculators, spell checkers, etc."
  },
  {
    "objectID": "slides/workshop-global-management.html#controlled-use-of-llms",
    "href": "slides/workshop-global-management.html#controlled-use-of-llms",
    "title": "Workshop: Global Management",
    "section": "Controlled use of LLMs",
    "text": "Controlled use of LLMs\n\n\n\n\n\n\n\nTask Category\nSpecific Tasks\n\n\n\n\nEditing tasks\nCreate/improve different versions of sections.\n\n\nTransitions\nWrite and compare transitions.\n\n\nImprove drafts\nCritique and refine drafts.\n\n\nWriting styles\nRewrite sections for different audiences.\n\n\nControversial statements\nIdentify controversial points and strengthen arguments.\n\n\nResearch journal\nKeep a diary and use LLM for reflection."
  },
  {
    "objectID": "slides/workshop-global-management.html#sport-vs.-writing",
    "href": "slides/workshop-global-management.html#sport-vs.-writing",
    "title": "Workshop: Global Management",
    "section": "Sport vs. writing",
    "text": "Sport vs. writing\n\n\n\nTechnological advancements in sports: a useful analogy for learning?\nDistinction between training and competition.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLZR Racer swim suit\nAI-base writing tools\n\n\n\n\nImprovement\nReduced Resistance, Increased Buoyancy\nImproved Grammar, Formulation, Content Creation\n\n\nFairness\nProvided an Unfair Advantage, Led to Record Performances\nConsidered Unfair in Academic Contexts\n\n\nImpact\nBanned to Maintain Competitive Integrity\nRaises Questions of Originality and Skill Development"
  },
  {
    "objectID": "slides/workshop-global-management.html#understanding-the-value-of-effort",
    "href": "slides/workshop-global-management.html#understanding-the-value-of-effort",
    "title": "Workshop: Global Management",
    "section": "Understanding the value of effort",
    "text": "Understanding the value of effort\n\nCheating can be a symptom that learners do not understand or value the importance of their own work.\nJust like in sport: if we take shortcuts during training, we won’t get fit.\nUnderstanding the purpose is important to endure discomfort.\nLearners need to understand what they are supposed to learn, why it is valuable, and why effort and discomfort are necessary."
  },
  {
    "objectID": "slides/workshop-global-management.html#fraud-triangle",
    "href": "slides/workshop-global-management.html#fraud-triangle",
    "title": "Workshop: Global Management",
    "section": "Fraud triangle",
    "text": "Fraud triangle"
  },
  {
    "objectID": "slides/workshop-global-management.html#learning-environments-that-promote-cheating",
    "href": "slides/workshop-global-management.html#learning-environments-that-promote-cheating",
    "title": "Workshop: Global Management",
    "section": "Learning Environments that promote cheating",
    "text": "Learning Environments that promote cheating\n\n\n\n\n\n\n\nFactors\nDescriptions\n\n\n\n\nHigh pressure\nHigh stakes increase cheating. Fear of failure reinforces this.\n\n\nLack of intrinsic motivation\nEngagement and relevance are important. Lacking these makes cheating more attractive.\n\n\nPerceived injustice\nUnfair grading leads to cheating.\n\n\nLow fear of getting caught\nLow risk encourages cheating.\n\n\nPeer influence\nWidespread cheating among peers pressures students to join in.\n\n\nLow self-efficacy\nDoubts about one’s own abilities increase cheating as the seemingly only option."
  },
  {
    "objectID": "slides/workshop-global-management.html#strategies-to-reduce-cheating",
    "href": "slides/workshop-global-management.html#strategies-to-reduce-cheating",
    "title": "Workshop: Global Management",
    "section": "Strategies to Reduce Cheating",
    "text": "Strategies to Reduce Cheating\n\n\n\n\n\n\n\nStrategies\nDescriptions\n\n\n\n\nFoster intrinsic motivation\nSpark genuine interest. Provide choices and practical applications.\n\n\nMastery learning\nClear learning objectives. Focus on mastery of content. Include constructive and corrective feedback in formative assessments.\n\n\nReduce pressure\nDiversify assessment methods. Use portfolios and low-stress tests to reduce anxiety.\n\n\nStrengthen self-efficacy\nProvide constructive feedback and promote peer learning (peer tutoring, peer review).\n\n\nCreate a culture of integrity\nOpen discussion about academic integrity. Set clear guidelines and promote community ethics."
  },
  {
    "objectID": "slides/workshop-global-management.html#academic-integrity-plagiarism",
    "href": "slides/workshop-global-management.html#academic-integrity-plagiarism",
    "title": "Workshop: Global Management",
    "section": "Academic Integrity: Plagiarism",
    "text": "Academic Integrity: Plagiarism\n\n\n\n\n\n\n\nTypes of Plagiarism\nDescription\n\n\n\n\nUnattributed use\nUsing the work or ideas of others without proper attribution.\n\n\nMinor changes or translations\nUsing the work of others with minor changes or translations without attribution.\n\n\nSelf-plagiarism\nReusing substantial parts of one’s own work without proper citation.\n\n\nJoint works\nReusing jointly written publications without proper acknowledgment."
  },
  {
    "objectID": "slides/workshop-global-management.html#academic-integrity-misconduct-in-authorship",
    "href": "slides/workshop-global-management.html#academic-integrity-misconduct-in-authorship",
    "title": "Workshop: Global Management",
    "section": "Academic Integrity: Misconduct in authorship",
    "text": "Academic Integrity: Misconduct in authorship\n\n\n\n\n\n\n\nTypes of Plagiarism\nDescription\n\n\n\n\nUnattributed use\nUsing the work or ideas of others without proper attribution.\n\n\nMinor changes or translations\nUsing the work of others with minor changes or translations without attribution.\n\n\nSelf-plagiarism\nReusing substantial parts of one’s own work without proper citation.\n\n\nJoint works\nReusing jointly written publications without proper acknowledgment."
  },
  {
    "objectID": "slides/workshop-global-management.html#how-to-cite-chatgpt",
    "href": "slides/workshop-global-management.html#how-to-cite-chatgpt",
    "title": "Workshop: Global Management",
    "section": "How to cite ChatGPT",
    "text": "How to cite ChatGPT\nE.g. APA Style: Cite as software (not as personal communication)."
  },
  {
    "objectID": "slides/workshop-global-management.html#documentating-ai-use",
    "href": "slides/workshop-global-management.html#documentating-ai-use",
    "title": "Workshop: Global Management",
    "section": "Documentating AI use",
    "text": "Documentating AI use\n\nSpecifying prompts works well for inexperienced users, but inadequately reflects complex processes.\nExperienced users work with dialogues and several tools, not monolithic prompts in ChatGPT.\nWorking with copilot (code): no traceable prompt input.\nInstead: Document the process, including the tools used and the steps taken.\n\nInclude used tools and steps in appendix, with optional graphical representation.\nServes both evaluation and self-reflection.\n\nIs documentation meaningful in the long term, once the use of AI-based tools has become commonplace?"
  },
  {
    "objectID": "slides/workshop-global-management.html#detecting-ai-use",
    "href": "slides/workshop-global-management.html#detecting-ai-use",
    "title": "Workshop: Global Management",
    "section": "Detecting AI use",
    "text": "Detecting AI use\n\nCan be detected by the use of specific vocabulary and phrases: “delve”, “vibrant”, “embark”, “it’s important to note”, ” based on the data provided”.\nDetection tools are not very useful, and can be easily circumvented.\nAccording to Fleckenstein et al. (2024)\n\nGenerative AI can write papers that are undetectable.\nTeachers overestimate their detection abilities."
  },
  {
    "objectID": "pages/tools.html",
    "href": "pages/tools.html",
    "title": "Promptly Educated //",
    "section": "",
    "text": "🤗 HuggingChat"
  },
  {
    "objectID": "pages/tools.html#open-assistants",
    "href": "pages/tools.html#open-assistants",
    "title": "Promptly Educated //",
    "section": "",
    "text": "🤗 HuggingChat"
  },
  {
    "objectID": "pages/tools.html#ai-tools",
    "href": "pages/tools.html#ai-tools",
    "title": "Promptly Educated //",
    "section": "AI Tools",
    "text": "AI Tools\n👉🏼 The largest AI tools directory (updated daily)"
  },
  {
    "objectID": "pages/tools.html#literatursuche",
    "href": "pages/tools.html#literatursuche",
    "title": "Promptly Educated //",
    "section": "Literatursuche",
    "text": "Literatursuche\n👉🏼 Elicit\n👉🏼 Consensus"
  },
  {
    "objectID": "pages/tools.html#prompt-engineering",
    "href": "pages/tools.html#prompt-engineering",
    "title": "Promptly Educated //",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\n👉🏼 Prompting Guide"
  },
  {
    "objectID": "pages/index.html",
    "href": "pages/index.html",
    "title": "Using AI in Education: Intermediate",
    "section": "",
    "text": "Designing effective prompts to instruct LLMs to generate a desired output is referred to as prompt engineering. This activity will guide you through the process of creating prompts for LLMs."
  },
  {
    "objectID": "pages/index.html#ki-kurse-der-virtuellen-akademie",
    "href": "pages/index.html#ki-kurse-der-virtuellen-akademie",
    "title": "Virtuelle Akademie",
    "section": "",
    "text": "Prompt-Labor: Basics zu KI-Sprachmodellen\n\n\n\nMöchtest du das volle Potential von Sprachmodellen wie ChatGPT ausschöpfen? In diesem Prompt-Labor tauchen wir sowohl in die Grundlagen von Sprachmodellen als auch in Techniken zur Erstellung effektiver Prompts ein.\nInhalt:\n\nWas sind KI-Sprachmodelle? Wie werden sie trainiert?\nWie generieren KI-Sprachmodelle Text?\nWie kommuniziere ich mit KI-Sprachmodellen? Wie schreibe ich gute Prompts?\n\nNächste Termine:\n23.02.2024, 14–16h\n22.04.2024, 10–12h\n www.bfh.ch/de/weiterbildung/kurse/prompt-labor-basics/\n\n\n\n\n\n\n\n\nPrompt-Labor Vertiefung: KI-Sprachmodelle in der Lehre nutzen\n\n\n\nMöchtest du Tools wie ChatGPT oder Chatbots für deinen Unterricht oder deine Weiterbildung nutzen? Das Prompt-Labor bietet Raum zum Experimentieren, Diskutieren und Entwickeln.\nInhalt:\n\nWie können Sprachmodelle genutzt werden, um Lehr- und Lernstrategien zu implementieren?\n\nNächste Termine:\n13.03.2024, 10–12h\n01.05.2024, 10–12h\n17.05.2024, 13.30–15.30\n www.bfh.ch/de/weiterbildung/kurse/prompt-labor-vertiefung/"
  },
  {
    "objectID": "pages/resources.html",
    "href": "pages/resources.html",
    "title": "Virtuelle Akademie",
    "section": "",
    "text": "KI-basierte Schreibtools in der Lehre – ChatGPT im Fokus\nKI-basierte Schreibtools in der Lehre – Knowledge Base"
  },
  {
    "objectID": "pages/resources.html#ki-orientierungshilfe-der-bfh",
    "href": "pages/resources.html#ki-orientierungshilfe-der-bfh",
    "title": "Virtuelle Akademie",
    "section": "KI Orientierungshilfe der BFH",
    "text": "KI Orientierungshilfe der BFH\n\nKI-basierte Schreibtools in der Lehre – ChatGPT im Fokus\nKI-basierte Schreibtools in der Lehre – Knowledge Base"
  },
  {
    "objectID": "pages/resources.html#bildung-6.0",
    "href": "pages/resources.html#bildung-6.0",
    "title": "Virtuelle Akademie",
    "section": "Bildung 6.0",
    "text": "Bildung 6.0\nDas Projekt Bildung 6.0 der Berner Fachhochschule stellt relevante und verlässliche Informationen und Empfehlungen zum richtigen Umgang mit KI-basierten Werkzeugen (KBW) für Studierende und Lehrende auf einer Online-Plattform bereit.\n\nProjekt Bildung 6.0"
  },
  {
    "objectID": "pages/resources.html#chatgpt-an-der-hochschule",
    "href": "pages/resources.html#chatgpt-an-der-hochschule",
    "title": "Virtuelle Akademie",
    "section": "ChatGPT an der Hochschule",
    "text": "ChatGPT an der Hochschule\n\nPrompts for Education: Enhancing Productivity & Learning\nUnlocking the Power of Generative AI Models and Systems such as GPT-4 and ChatGPT for Higher Education\nÜberblick über KI-Tools im Kontext von akademischen Lese- und Schreibprozessen\nChatGPT im Hochschulkontext – eine kommentierte Linksammlung\nUni Bern: Chatbots in der Hochschullehre"
  },
  {
    "objectID": "pages/resources.html#youtube",
    "href": "pages/resources.html#youtube",
    "title": "Virtuelle Akademie",
    "section": "Youtube",
    "text": "Youtube\nLarge language models from scratch\n\nHow do large language models work: part 1\nHow do large language models work: part 2\n\nTutorials zu Prompting\n\nChatGPT Mega Prompts"
  },
  {
    "objectID": "pages/resources.html#how-does-gpt-work",
    "href": "pages/resources.html#how-does-gpt-work",
    "title": "Virtuelle Akademie",
    "section": "How does GPT work?",
    "text": "How does GPT work?\n\nGenerative AI exists because of the transformer (Financial Times 12/09/2023)"
  },
  {
    "objectID": "pages/resources.html#wissenschaftliches-arbeiten",
    "href": "pages/resources.html#wissenschaftliches-arbeiten",
    "title": "Virtuelle Akademie",
    "section": "Wissenschaftliches Arbeiten",
    "text": "Wissenschaftliches Arbeiten\n\nChatGPT zitieren\nRechtliche Fragen\nDidaktische Und Rechtliche Perspektiven Auf Ki-Gestütztes Schreiben In Der Hochschulbildung (Salden 2023)"
  },
  {
    "objectID": "pages/resources.html#ethische-fragen",
    "href": "pages/resources.html#ethische-fragen",
    "title": "Virtuelle Akademie",
    "section": "Ethische Fragen",
    "text": "Ethische Fragen\n\nPrekäre Klickarbeit hinter den Kulissen von ChatGPT\nTraumatische Klickarbeit: Die Menschen hinter ChatGPT"
  },
  {
    "objectID": "pages/activity-global-management.html",
    "href": "pages/activity-global-management.html",
    "title": "Hands-On Practice: Prompting",
    "section": "",
    "text": "Designing effective prompts to instruct LLMs to generate a desired output is referred to as prompt engineering. This activity will guide you through the process of creating prompts for LLMs."
  },
  {
    "objectID": "pages/activity-global-management.html#general-tips",
    "href": "pages/activity-global-management.html#general-tips",
    "title": "Hands-On Practice: Prompting",
    "section": "General tips",
    "text": "General tips\nOpenAI give a set of  strategies for using their models. If you need examples, this might be a good place to start.\nThe strategies include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving GPT ‘time to think’\nusing external tools\n\nSome general techniques are:\n\nNumbered Steps:: For sequential tasks, use numbered steps. This helps the model understand the sequence of actions.\nUse delimiters: To separate various parts of the prompt (e.g. \", `,, ', |, #, …).\nFew-shot prompting: Provide a few examples for guidance.\n\nCombining these techniques, a template prompt might look like this:\n\n\n\n\n\n\nTemplate\n\n\n\n\nRole: who is being simulated?\nTask: what is to be done?\nSteps: what are the steps to complete the task?\nContext: what is the context of the task?\nGoal: what is the goal of the task?\nFormat: what is the format of the output? How long should it be?\n\n\n\nRemember to structure your prompt in a way that is clear and easy to understand. You can use markdown to format your prompt, and you instruct the mode to format its response using markdown.\n\nExample\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are an expert on the topic of university education and didactics. Explain the concept of “flipped classroom” to a group of teachers. Use markdown to format your response. Keep you explanation concise and to the point.\n\n\nDifferent persona:\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are 13 year old high school student. Explain the concept of “flipped classroom” to your friends. Use markdown to format your response. Keep you explanation concise and to the point.\n\n\nAsk the model to output a table:\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are a high school teacher. Give me a table containing Greek letters in one column, their pronunciation in the second column, and examples of usage in the third column. Give me a maximum of 6 rows."
  },
  {
    "objectID": "pages/activity-global-management.html#structured-prompting-techniques",
    "href": "pages/activity-global-management.html#structured-prompting-techniques",
    "title": "Hands-On Practice: Prompting",
    "section": "Structured prompting techniques",
    "text": "Structured prompting techniques\n\nIn-Context Learning: Provide examples within the prompt\n\nExplanation\nIn-Context Learning involves providing the language model with examples or context within the prompt itself. This technique helps guide the model’s responses by demonstrating the desired output format or type of information.\n\n\nTechniques\n\nFew-Shot Prompting: Provide a few examples of the desired output before asking for a new response.\nZero-Shot Prompting: Ask the model to perform a task without any examples, relying on its pre-trained knowledge.\n\n\n\nExample\n\n\n\n\n\n\n Few-Shot Prompting:\n\n\n\nSummarize the main findings of these research paper abstracts:\n\nAbstract: [Insert first abstract] Summary: The study found that increased physical activity is associated with improved cognitive function in older adults.\nAbstract: [Insert second abstract] Summary: The research demonstrated a positive correlation between employee satisfaction and productivity in remote work environments.\n\nNow summarize this new abstract: [Insert new abstract to be summarized]\n\n\n\n\n\n\n\n\nHands-on Exercise\n\n\n\n\nChoose a topic you’re interested in. If you would like to use an AI-based tool for literature research, you can use Elicit.\nCreate zero-shot and few-shot prompts to extract the research question, methodology, and main findings from the abstracts of three research papers.\n\n\n\n\n\n\nThought Generation: Instruct the model to think step-by-step\n\nExplanation\nThought generation techniques encourage the model to show its reasoning process, making the output more transparent and often more accurate.\n\n\nTechniques\nChain-of-Thought (CoT) Prompting: Ask the model to break down its thinking into steps.\n\nZero-Shot CoT: Request step-by-step reasoning without providing examples.\nFew-Shot CoT: Provide examples of step-by-step reasoning before asking for a new response.\n\n\n\nExample Prompt (Chain-of-Thought):\n\n\n\n\n\n\n Prompt:\n\n\n\nAnalyze the methodology of the following research study. Think through this step-by-step: 1. Identify the research design. 2. Evaluate the appropriateness of the chosen methods. 3. Assess potential limitations or biases. 4. Consider alternative approaches that could have been used.\n[Insert methodology section of a research paper]\n\n\n\n\n\nDecomposition Techniques: Break down tasks into subtasks\n\nExplanation\nDecomposition techniques involve breaking down complex tasks into smaller, more manageable subtasks. This approach can lead to more accurate and comprehensive responses.\n\n\nTechniques\n\nLeast-to-Most Prompting: Start with the simplest subtask and gradually increase complexity. More info here:  Least-to-Most Prompting\nPlan-and-Solve Prompting: Separate the task into a planning phase and an execution phase.\n\n\n\nExample Prompt (Plan-and-Solve):\n\n\n\n\n\n\n Prompt:\n\n\n\nWe need to conduct a systematic literature review on [specific topic]. Let’s approach this in two phases:\nPlanning Phase: 1. Outline the main steps needed for this systematic review. 2. For each step, briefly describe what needs to be considered.\nSolving Phase: Now, let’s address each step in detail, providing specific strategies and methodologies."
  },
  {
    "objectID": "pages/index.html#general-tips",
    "href": "pages/index.html#general-tips",
    "title": "Using AI in Education: Intermediate",
    "section": "General tips",
    "text": "General tips\nOpenAI give a set of  strategies for using their models. If you need examples, this might be a good place to start.\nThe strategies include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving GPT ‘time to think’\nusing external tools\n\nSome general techniques are:\n\nNumbered Steps:: For sequential tasks, use numbered steps. This helps the model understand the sequence of actions.\nUse delimiters: To separate various parts of the prompt (e.g. \", `,, ', |, #, …).\nFew-shot prompting: Provide a few examples for guidance.\n\nCombining these techniques, a template prompt might look like this:\n\n\n\n\n\n\nTemplate\n\n\n\n\nRole: who is being simulated?\nTask: what is to be done?\nSteps: what are the steps to complete the task?\nContext: what is the context of the task?\nGoal: what is the goal of the task?\nFormat: what is the format of the output? How long should it be?\n\n\n\nRemember to structure your prompt in a way that is clear and easy to understand. You can use markdown to format your prompt, and you instruct the mode to format its response using markdown.\n\nExample\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are an expert on the topic of university education and didactics. Explain the concept of “flipped classroom” to a group of teachers. Use markdown to format your response. Keep you explanation concise and to the point.\n\n\nDifferent persona:\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are 13 year old high school student. Explain the concept of “flipped classroom” to your friends. Use markdown to format your response. Keep you explanation concise and to the point.\n\n\nAsk the model to output a table:\n\n\n\n\n\n\n Prompt:\n\n\n\nYou are a high school teacher. Give me a table containing Greek letters in one column, their pronunciation in the second column, and examples of usage in the third column. Give me a maximum of 6 rows."
  },
  {
    "objectID": "pages/index.html#structured-prompting-techniques",
    "href": "pages/index.html#structured-prompting-techniques",
    "title": "Using AI in Education: Intermediate",
    "section": "Structured prompting techniques",
    "text": "Structured prompting techniques\n\nIn-Context Learning: Provide examples within the prompt\n\nExplanation\nIn-Context Learning involves providing the language model with examples or context within the prompt itself. This technique helps guide the model’s responses by demonstrating the desired output format or type of information.\n\n\nTechniques\n\nFew-Shot Prompting: Provide a few examples of the desired output before asking for a new response.\nZero-Shot Prompting: Ask the model to perform a task without any examples, relying on its pre-trained knowledge.\n\n\n\nExample\n\n\n\n\n\n\n Few-Shot Prompting:\n\n\n\nSummarize the main findings of these research paper abstracts:\n\nAbstract: [Insert first abstract] Summary: The study found that increased physical activity is associated with improved cognitive function in older adults.\nAbstract: [Insert second abstract] Summary: The research demonstrated a positive correlation between employee satisfaction and productivity in remote work environments.\n\nNow summarize this new abstract: [Insert new abstract to be summarized]\n\n\n\n\n\n\n\n\nHands-on Exercise\n\n\n\n\nChoose a topic you’re interested in. If you would like to use an AI-based tool for literature research, you can use Elicit.\nCreate zero-shot and few-shot prompts to extract the research question, methodology, and main findings from the abstracts of three research papers.\n\n\n\n\n\n\nThought Generation: Instruct the model to think step-by-step\n\nExplanation\nThought generation techniques encourage the model to show its reasoning process, making the output more transparent and often more accurate.\n\n\nTechniques\nChain-of-Thought (CoT) Prompting: Ask the model to break down its thinking into steps.\n\nZero-Shot CoT: Request step-by-step reasoning without providing examples.\nFew-Shot CoT: Provide examples of step-by-step reasoning before asking for a new response.\n\n\n\nExample Prompt (Chain-of-Thought):\n\n\n\n\n\n\n Prompt:\n\n\n\nAnalyze the methodology of the following research study. Think through this step-by-step: 1. Identify the research design. 2. Evaluate the appropriateness of the chosen methods. 3. Assess potential limitations or biases. 4. Consider alternative approaches that could have been used.\n[Insert methodology section of a research paper]\n\n\n\n\n\nDecomposition Techniques: Break down tasks into subtasks\n\nExplanation\nDecomposition techniques involve breaking down complex tasks into smaller, more manageable subtasks. This approach can lead to more accurate and comprehensive responses.\n\n\nTechniques\n\nLeast-to-Most Prompting: Start with the simplest subtask and gradually increase complexity. More info here:  Least-to-Most Prompting\nPlan-and-Solve Prompting: Separate the task into a planning phase and an execution phase.\n\n\n\nExample Prompt (Plan-and-Solve):\n\n\n\n\n\n\n Prompt:\n\n\n\nWe need to conduct a systematic literature review on [specific topic]. Let’s approach this in two phases:\nPlanning Phase: 1. Outline the main steps needed for this systematic review. 2. For each step, briefly describe what needs to be considered.\nSolving Phase: Now, let’s address each step in detail, providing specific strategies and methodologies."
  },
  {
    "objectID": "slides/presentation-1.html#what-is-artifical-intelligence",
    "href": "slides/presentation-1.html#what-is-artifical-intelligence",
    "title": "Presentation 1",
    "section": "What is Artifical Intelligence?",
    "text": "What is Artifical Intelligence?\n\n\n\n\nA branch of computer science that aims to create machines that can perform tasks that typically require human intelligence."
  },
  {
    "objectID": "slides/presentation-1.html#what-is-a-large-language-model",
    "href": "slides/presentation-1.html#what-is-a-large-language-model",
    "title": "Presentation 1",
    "section": "What is a Large Language Model?",
    "text": "What is a Large Language Model?\n\n\n\n\nAn LLM is a type of generative AI model that is trained to predict the next word following the input (prompt)."
  },
  {
    "objectID": "slides/presentation-1.html#how-to-train-a-language-model",
    "href": "slides/presentation-1.html#how-to-train-a-language-model",
    "title": "Presentation 1",
    "section": "How to train a language model",
    "text": "How to train a language model\n\nAn LLM learns to predict the next word in a sequence, given the previous words: \\[ P(word | context) \\]\nThink of as “fancy autocomplete” (but very very powerful and sopisticated)"
  },
  {
    "objectID": "slides/presentation-1.html#how-does-an-llm-generate-text",
    "href": "slides/presentation-1.html#how-does-an-llm-generate-text",
    "title": "Presentation 1",
    "section": "How does an LLM generate text?",
    "text": "How does an LLM generate text?"
  },
  {
    "objectID": "slides/presentation-1.html#sampling",
    "href": "slides/presentation-1.html#sampling",
    "title": "Presentation 1",
    "section": "Sampling",
    "text": "Sampling"
  },
  {
    "objectID": "slides/presentation-1.html#auto-regressive-generation",
    "href": "slides/presentation-1.html#auto-regressive-generation",
    "title": "Presentation 1",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation\nText is generated one word at a time (actually tokens, not words).\n\n\n\n\n\n Generated text depends on the generative model and the context.\n Every word (token) is given an equal amount time (computation per token is constant)."
  },
  {
    "objectID": "slides/presentation-1.html#auto-regressive-generation-1",
    "href": "slides/presentation-1.html#auto-regressive-generation-1",
    "title": "Presentation 1",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation"
  },
  {
    "objectID": "slides/presentation-1.html#foundation-models",
    "href": "slides/presentation-1.html#foundation-models",
    "title": "Presentation 1",
    "section": "Foundation models",
    "text": "Foundation models\nA foundation model, or large language model (LLM):\n\nis a type of machine learning model that is trained to predict the next word following the input (prompt).\nis trained “simply” to predict the next word following a sequence of words.\ndoes not necessarily produce human-like conversations.\n\n\n\n\n: What is the capital of France?\n: What is the capital of Germany? What is the capital of Italy? . .."
  },
  {
    "objectID": "slides/presentation-1.html#training-process",
    "href": "slides/presentation-1.html#training-process",
    "title": "Presentation 1",
    "section": "Training process",
    "text": "Training process\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/presentation-1.html#assistant-models",
    "href": "slides/presentation-1.html#assistant-models",
    "title": "Presentation 1",
    "section": "Assistant models",
    "text": "Assistant models\nTrained (fine-tuned) to have conversations: turn-taking, question answering, not being rude/sexist/racist.\n\n\n\n\n\n\nFoundation model has learned to predict all kinds of text, including both desirable and undesirable text.\nFine-tuning narrows down the space of all possible output to only desirable, human-like dialogue.\nModel is aligned with the values of the fine-tuner."
  },
  {
    "objectID": "slides/presentation-1.html#how-do-chatbots-work",
    "href": "slides/presentation-1.html#how-do-chatbots-work",
    "title": "Presentation 1",
    "section": "How do Chatbots work?",
    "text": "How do Chatbots work?\n\n\nDesigned to present the illusion of a conversation between two entities."
  },
  {
    "objectID": "slides/presentation-1.html#how-do-chatbots-actually-work",
    "href": "slides/presentation-1.html#how-do-chatbots-actually-work",
    "title": "Presentation 1",
    "section": "How do chatbots actually work?",
    "text": "How do chatbots actually work?"
  },
  {
    "objectID": "slides/presentation-1.html#an-assistant-model-is-a-conversation-simulator",
    "href": "slides/presentation-1.html#an-assistant-model-is-a-conversation-simulator",
    "title": "Presentation 1",
    "section": "An assistant model is a conversation simulator",
    "text": "An assistant model is a conversation simulator\n\n\n\n\n\nAn assistant is trained to respond to user prompts in a human-like way.\nSimulates possible human conversations.\nHas no intentions. It is not an entity with its own goals.\nDoes not have a “personality” or “character” in the traditional sense. It can be thought of as a role-playing simulator.\nHas no concept of “truth” or “lying”. The model is not trying to deceive the user, it is simply trying to respond in a human-like way."
  },
  {
    "objectID": "slides/presentation-1.html#capabilities-and-limitations",
    "href": "slides/presentation-1.html#capabilities-and-limitations",
    "title": "Presentation 1",
    "section": "Capabilities and limitations",
    "text": "Capabilities and limitations\n\n\nWhat are LLMs good at?\n\nFixing grammar, bad writing, etc.\nRephrasing\nAnalyzing texts\nWriting computer code\nAnswering questions about a knowledge base\nTranslating languages\nCreating structured output\nFactual output with external documents or web search\n\n\nLimitations\n\nThey make stuff up (hallucinate)\nThey learn biases from the training data\nWeird vocabulary, e.g. delve\n(Chatbots have privacy issues)"
  },
  {
    "objectID": "slides/presentation-1.html#hallucination",
    "href": "slides/presentation-1.html#hallucination",
    "title": "Presentation 1",
    "section": "Hallucination",
    "text": "Hallucination\n\n\n\n\n\nLLMs can generate text that is not true, or not based on any real-world knowledge.\nThis is known as “hallucination”. A better term would be “confabulation”."
  },
  {
    "objectID": "slides/presentation-1.html#can-an-llm-tell-the-truth",
    "href": "slides/presentation-1.html#can-an-llm-tell-the-truth",
    "title": "Presentation 1",
    "section": "Can an LLM tell the truth?",
    "text": "Can an LLM tell the truth?\n\nHow would you know if an LLM is able to give you factual information?\nHow would you test this?\n\n\n\n\n: What is the capital of Uzbekistan?\n: Tashkent\n\n\n\nIt looks like the LLM knows the capital of Uzbekistan1.\nWhat it is actually doing is responding with the most likely sequence following the question."
  },
  {
    "objectID": "slides/presentation-1.html#knowledge-base",
    "href": "slides/presentation-1.html#knowledge-base",
    "title": "Presentation 1",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\nA knowledge base is a collection of facts about the world.\n\nYou can ask (retrieve) and tell (store) facts.\n\nAn LLM is not a knowledge base.\n\nLLMs generate text based on on how probable the next word is given the context, not based on stored facts."
  },
  {
    "objectID": "slides/presentation-1.html#biases",
    "href": "slides/presentation-1.html#biases",
    "title": "Presentation 1",
    "section": "Biases",
    "text": "Biases\n\n\n\n\n\n\n\n\nBiases in LLMs\nSource\nExamples\n\n\n\n\nTraining data bias\nText from internet, books, articles.\nStereotypes reflecting gender, race, religion.\n\n\nRepresentation bias\nUnderrepresented groups/perspectives in data.\nLess accurate responses for minority cultures.\n\n\nAlgorithmic bias\nTraining and fine-tuning algorithms.\nOptimizations for fluency and coherence may lead to preference for dominant cultural narratives.\n\n\nUser interaction bias\nAdaptation based on user interactions.\nIncreased biased or harmful content generation."
  },
  {
    "objectID": "slides/presentation-1.html#privacy-concerns",
    "href": "slides/presentation-1.html#privacy-concerns",
    "title": "Presentation 1",
    "section": "Privacy concerns",
    "text": "Privacy concerns\n\n\n\n\n\n\n\n\nPrivacy Concerns\nIssue\nExamples\n\n\n\n\nData memorization\nMemorizing sensitive information.\nReproducing phone numbers, addresses.\n\n\nTraining data leakage\nUnauthorized dissemination of confidential data.\nSummarizing proprietary documents.\n\n\nUser query logging\nStoring sensitive user interactions.\nExposing private queries if data is mishandled.\n\n\nQueries used for training\nUser queries may be used for further training.\nPersonal data in queries could be inadvertently included in training data."
  },
  {
    "objectID": "slides/presentation-1.html#prompting",
    "href": "slides/presentation-1.html#prompting",
    "title": "Presentation 1",
    "section": "Prompting",
    "text": "Prompting"
  },
  {
    "objectID": "slides/presentation-1.html#what-is-a-prompt",
    "href": "slides/presentation-1.html#what-is-a-prompt",
    "title": "Presentation 1",
    "section": "What is a prompt?",
    "text": "What is a prompt?\n\nAn LLM’s task is to complete text.\nA prompt is a piece of text (instruction) that is given to a language model to complete.\n\n\n\n\nPROMPT : Write a haiku about a workshop on large language models.\nASSISTANT : Whispers of circuits,\nKnowledge blooms in bytes and bits,\nModel learns and fits.\n\n\n\n\nThe response is generated as continuation of, and conditioned on, the prompt.\n\n\nMore technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt."
  },
  {
    "objectID": "slides/presentation-1.html#prompt-engineering",
    "href": "slides/presentation-1.html#prompt-engineering",
    "title": "Presentation 1",
    "section": "Prompt engineering",
    "text": "Prompt engineering\n\n\n\n\n\nLLMs learn to do things they were not explicitly trained to do: translation, reasoning, etc. \nOften, these capabilities need to be “unlocked” by the right prompt. \n\n\n\nBut what is the right prompt?\nThe answer is very similar to what you would tell a human dialogue partner/assistant.\nYou can increase the probability of getting the desired output by providing context and examples."
  },
  {
    "objectID": "slides/presentation-1.html#basics-of-prompting",
    "href": "slides/presentation-1.html#basics-of-prompting",
    "title": "Presentation 1",
    "section": "Basics of prompting",
    "text": "Basics of prompting\nOpenAI give a set of strategies for using their models effectively:\n Prompt engineering\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving the LLM ‘time to think’\nusing external tools"
  },
  {
    "objectID": "slides/presentation-1.html#writing-clear-instructions",
    "href": "slides/presentation-1.html#writing-clear-instructions",
    "title": "Presentation 1",
    "section": "Writing clear instructions",
    "text": "Writing clear instructions\n\n\n\nInstructions should be clear and unambiguous.\nThink of an LLM as a role-playing conversation simulator: Indicate which role the model (persona) should adopt.\n\n\n\n\n\n\nInclude details in your query to get more relevant answers\nAsk the model to adopt a persona\nUse delimiters to clearly indicate distinct parts of the input\nSpecify the steps required to complete a task\nProvide examples\nSpecify the desired length of the output"
  },
  {
    "objectID": "slides/presentation-1.html#adopt-a-persona-role",
    "href": "slides/presentation-1.html#adopt-a-persona-role",
    "title": "Presentation 1",
    "section": "Adopt a persona (role)",
    "text": "Adopt a persona (role)\n\n\n\n: You are an expert on learning techniques. Explain the concept of ‘flipped classroom’ in one paragraph.\n\n\n\n\n\n\n: You are an expert financial derivatives. Explain the concept of ‘flipped classroom’ in one paragraph."
  },
  {
    "objectID": "slides/presentation-1.html#provide-reference-texts",
    "href": "slides/presentation-1.html#provide-reference-texts",
    "title": "Presentation 1",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\nProvide a model with trusted and relevant information.\nThen instruct the model to use the provided information to compose its answer.\n\n Instruct the model to answer using a reference text\n\n\n\nThis can be extended to retrieval-augmented generation (RAG). First create a database of documents, then retrieve the most relevant documents, based on a user’s query. These are then included in the prompt to the model. The model is instructed to use the information in the documents to compose its answer."
  },
  {
    "objectID": "slides/presentation-1.html#create-structured-output",
    "href": "slides/presentation-1.html#create-structured-output",
    "title": "Presentation 1",
    "section": "Create structured output",
    "text": "Create structured output\n\nExplanation: Instruct the model to generate structured output.\nE.g. provide a table, a list, a diagram, etc.\nUse delimiters to indicate distinct parts of the input.\nExample: Extract information from a text and present it in a table."
  },
  {
    "objectID": "slides/presentation-1.html#structured-prompting-techniques",
    "href": "slides/presentation-1.html#structured-prompting-techniques",
    "title": "Presentation 1",
    "section": "Structured prompting techniques",
    "text": "Structured prompting techniques\n\nIn-Context Learning: Provide examples within the prompt.\nThought Generation: Instruct the model to think step-by-step.\nDecomposition Techniques: Break down tasks into subtasks.\n\n(Schulhoff et al. 2024)"
  },
  {
    "objectID": "slides/presentation-1.html#in-context-learning",
    "href": "slides/presentation-1.html#in-context-learning",
    "title": "Presentation 1",
    "section": "In-Context learning",
    "text": "In-Context learning\n\nExplanation: Providing examples or context within the prompt itself.\nFew-shot prompting: Give a few examples.\n\nExample: Translate the following sentences:\n\nEnglish: ‘What time is it?’ -&gt; French: ‘Quelle heure est-il?’\nEnglish: ‘Where is the library?’ -&gt; French:\n\n\nZero-shot prompting: No examples, relies on pre-trained knowledge.\n\nExample: Translate the following sentence…"
  },
  {
    "objectID": "slides/presentation-1.html#thought-generation",
    "href": "slides/presentation-1.html#thought-generation",
    "title": "Presentation 1",
    "section": "Thought generation",
    "text": "Thought generation\n\nExplanation: Encourages the model to show its reasoning process.\nChain-of-Thought (CoT) prompting: encourages the LLM to “explain” its intermediate reasoning steps.\nCan often be induced by simply instructing the model to think step-by-step or Take a deep breath and work on this problem step-by-step (Yang et al. 2023)."
  },
  {
    "objectID": "slides/presentation-1.html#chain-of-thought-example",
    "href": "slides/presentation-1.html#chain-of-thought-example",
    "title": "Presentation 1",
    "section": "Chain-of-Thought example",
    "text": "Chain-of-Thought example\nInstead of this:\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Yes or no?\n\n\n\nDo this:\n\n\n\n: Is this statement correct? The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\nReason through the problem step-by-step. Start by identifying the odd numbers. Next, add them up. Finally, determine if the sum is even or odd. Write down your reasoning steps in a numbered list.\n\n\n\n\nWhy does this work?"
  },
  {
    "objectID": "slides/presentation-1.html#decomposition-techniques",
    "href": "slides/presentation-1.html#decomposition-techniques",
    "title": "Presentation 1",
    "section": "Decomposition techniques",
    "text": "Decomposition techniques\n\nExplanation: Force the LLM to break down complex tasks into manageable subtasks.\nLeast-to-Most Prompting: Start simple, increase complexity.\n\nExample: List items, calculate cost…\n\nPlan-and-Solve Prompting: Separate planning and execution phases.\n\nExample: Understand the problem, devise a plan…"
  },
  {
    "objectID": "slides/presentation-1.html#hands-on-practice-prompting",
    "href": "slides/presentation-1.html#hands-on-practice-prompting",
    "title": "Presentation 1",
    "section": "Hands-on practice: Prompting",
    "text": "Hands-on practice: Prompting\n Open this activity.\n\nPractice writing prompts for different tasks ( 20 minutes).\nWrite an essay using an LLM, and then critique someone else’s essay ( 30 minutes).\n\n  If you need further help with prompting techniques, see these websites:\n\n Learn prompting\n Prompting guide\n OpenAI cookbook"
  },
  {
    "objectID": "slides/presentation-1.html#chatgpt-edu",
    "href": "slides/presentation-1.html#chatgpt-edu",
    "title": "Presentation 1",
    "section": "ChatGPT Edu",
    "text": "ChatGPT Edu\n\n\n \n\n\n\n\nAccess to GPT-4o, excelling in text interpretation, coding, and mathematics\nData analytics, web browsing, and document summarization\nBuild GPTs, custom versions of ChatGPT, and share them within university workspaces\nSignificantly higher message limits than the free version of ChatGPT\nImproved language capabilities across quality and speed, with over 50 languages supported\nRobust security, data privacy, and administrative controls\nConversations and data are not used to train OpenAI models"
  },
  {
    "objectID": "slides/presentation-1.html#gpts",
    "href": "slides/presentation-1.html#gpts",
    "title": "Presentation 1",
    "section": "GPTs",
    "text": "GPTs"
  },
  {
    "objectID": "slides/presentation-1.html#hands-on-practice-gpts",
    "href": "slides/presentation-1.html#hands-on-practice-gpts",
    "title": "Presentation 1",
    "section": "Hands-on practice: GPTs",
    "text": "Hands-on practice: GPTs\n\nTry out custom GPTs from various categories in the GPT store.\nDiscuss with your neighbour\n\nDid you discover any useful GPTs?\nWhat are the benefits and limitations of using GPTs in the classroom?"
  },
  {
    "objectID": "slides/presentation-1.html#extended-cognition",
    "href": "slides/presentation-1.html#extended-cognition",
    "title": "Presentation 1",
    "section": "Extended cognition",
    "text": "Extended cognition\n\n\n\nAccording to Clark and Chalmers (1998), cognitive processes may extend to external objects.\nKrakauer (2016) distinguishes between complementary and competitive cognitive artifacts.\n\nComplementary: numbers, abacus\nCompetetive: calculator, GPS\n\nWhat kind of artefact will AI turn out to be?"
  },
  {
    "objectID": "slides/presentation-1.html#deskilling-vs.-upskilling",
    "href": "slides/presentation-1.html#deskilling-vs.-upskilling",
    "title": "Presentation 1",
    "section": "Deskilling vs. upskilling",
    "text": "Deskilling vs. upskilling"
  },
  {
    "objectID": "slides/presentation-1.html#writing-tasks-in-the-ai-era",
    "href": "slides/presentation-1.html#writing-tasks-in-the-ai-era",
    "title": "Presentation 1",
    "section": "Writing tasks in the AI era",
    "text": "Writing tasks in the AI era\n\nWriting is a core skill: critical thinking, persuasion, argumentation, understanding.\nText creation is secondary in learning: focus is on underlying skills.\nLearning objectives: Benefits of writing tasks should be clearly and convincingly conveyed.\nStudents should be equipped for effective (controlled) use of AI."
  },
  {
    "objectID": "slides/presentation-1.html#ai-can-do-my-homework",
    "href": "slides/presentation-1.html#ai-can-do-my-homework",
    "title": "Presentation 1",
    "section": "AI can do my homework",
    "text": "AI can do my homework\n\nWe can think of this as cheating.\nMore useful: cheating means bypassing useful cognition and therefore missing out on learning.\nCheating an ethics problem.\nBypassing cognition is a learning problem.\nNot a new problem: books, encyclopedias, calculators, spell checkers, etc."
  },
  {
    "objectID": "slides/presentation-1.html#controlled-use-of-llms",
    "href": "slides/presentation-1.html#controlled-use-of-llms",
    "title": "Presentation 1",
    "section": "Controlled use of LLMs",
    "text": "Controlled use of LLMs\n\n\n\n\n\n\n\nTask Category\nSpecific Tasks\n\n\n\n\nEditing tasks\nCreate/improve different versions of sections.\n\n\nTransitions\nWrite and compare transitions.\n\n\nImprove drafts\nCritique and refine drafts.\n\n\nWriting styles\nRewrite sections for different audiences.\n\n\nControversial statements\nIdentify controversial points and strengthen arguments.\n\n\nResearch journal\nKeep a diary and use LLM for reflection."
  },
  {
    "objectID": "slides/presentation-1.html#sport-vs.-writing",
    "href": "slides/presentation-1.html#sport-vs.-writing",
    "title": "Presentation 1",
    "section": "Sport vs. writing",
    "text": "Sport vs. writing\n\n\n\nTechnological advancements in sports: a useful analogy for learning?\nDistinction between training and competition.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLZR Racer swim suit\nAI-base writing tools\n\n\n\n\nImprovement\nReduced Resistance, Increased Buoyancy\nImproved Grammar, Formulation, Content Creation\n\n\nFairness\nProvided an Unfair Advantage, Led to Record Performances\nConsidered Unfair in Academic Contexts\n\n\nImpact\nBanned to Maintain Competitive Integrity\nRaises Questions of Originality and Skill Development"
  },
  {
    "objectID": "slides/presentation-1.html#understanding-the-value-of-effort",
    "href": "slides/presentation-1.html#understanding-the-value-of-effort",
    "title": "Presentation 1",
    "section": "Understanding the value of effort",
    "text": "Understanding the value of effort\n\nCheating can be a symptom that learners do not understand or value the importance of their own work.\nJust like in sport: if we take shortcuts during training, we won’t get fit.\nUnderstanding the purpose is important to endure discomfort.\nLearners need to understand what they are supposed to learn, why it is valuable, and why effort and discomfort are necessary."
  },
  {
    "objectID": "slides/presentation-1.html#fraud-triangle",
    "href": "slides/presentation-1.html#fraud-triangle",
    "title": "Presentation 1",
    "section": "Fraud triangle",
    "text": "Fraud triangle"
  },
  {
    "objectID": "slides/presentation-1.html#learning-environments-that-promote-cheating",
    "href": "slides/presentation-1.html#learning-environments-that-promote-cheating",
    "title": "Presentation 1",
    "section": "Learning Environments that promote cheating",
    "text": "Learning Environments that promote cheating\n\n\n\n\n\n\n\nFactors\nDescriptions\n\n\n\n\nHigh pressure\nHigh stakes increase cheating. Fear of failure reinforces this.\n\n\nLack of intrinsic motivation\nEngagement and relevance are important. Lacking these makes cheating more attractive.\n\n\nPerceived injustice\nUnfair grading leads to cheating.\n\n\nLow fear of getting caught\nLow risk encourages cheating.\n\n\nPeer influence\nWidespread cheating among peers pressures students to join in.\n\n\nLow self-efficacy\nDoubts about one’s own abilities increase cheating as the seemingly only option."
  },
  {
    "objectID": "slides/presentation-1.html#strategies-to-reduce-cheating",
    "href": "slides/presentation-1.html#strategies-to-reduce-cheating",
    "title": "Presentation 1",
    "section": "Strategies to Reduce Cheating",
    "text": "Strategies to Reduce Cheating\n\n\n\n\n\n\n\nStrategies\nDescriptions\n\n\n\n\nFoster intrinsic motivation\nSpark genuine interest. Provide choices and practical applications.\n\n\nMastery learning\nClear learning objectives. Focus on mastery of content. Include constructive and corrective feedback in formative assessments.\n\n\nReduce pressure\nDiversify assessment methods. Use portfolios and low-stress tests to reduce anxiety.\n\n\nStrengthen self-efficacy\nProvide constructive feedback and promote peer learning (peer tutoring, peer review).\n\n\nCreate a culture of integrity\nOpen discussion about academic integrity. Set clear guidelines and promote community ethics."
  },
  {
    "objectID": "slides/presentation-1.html#academic-integrity-plagiarism",
    "href": "slides/presentation-1.html#academic-integrity-plagiarism",
    "title": "Presentation 1",
    "section": "Academic Integrity: Plagiarism",
    "text": "Academic Integrity: Plagiarism\n\n\n\n\n\n\n\nTypes of Plagiarism\nDescription\n\n\n\n\nUnattributed use\nUsing the work or ideas of others without proper attribution.\n\n\nMinor changes or translations\nUsing the work of others with minor changes or translations without attribution.\n\n\nSelf-plagiarism\nReusing substantial parts of one’s own work without proper citation.\n\n\nJoint works\nReusing jointly written publications without proper acknowledgment."
  },
  {
    "objectID": "slides/presentation-1.html#academic-integrity-misconduct-in-authorship",
    "href": "slides/presentation-1.html#academic-integrity-misconduct-in-authorship",
    "title": "Presentation 1",
    "section": "Academic Integrity: Misconduct in authorship",
    "text": "Academic Integrity: Misconduct in authorship\n\n\n\n\n\n\n\nTypes of Plagiarism\nDescription\n\n\n\n\nUnattributed use\nUsing the work or ideas of others without proper attribution.\n\n\nMinor changes or translations\nUsing the work of others with minor changes or translations without attribution.\n\n\nSelf-plagiarism\nReusing substantial parts of one’s own work without proper citation.\n\n\nJoint works\nReusing jointly written publications without proper acknowledgment."
  },
  {
    "objectID": "slides/presentation-1.html#how-to-cite-chatgpt",
    "href": "slides/presentation-1.html#how-to-cite-chatgpt",
    "title": "Presentation 1",
    "section": "How to cite ChatGPT",
    "text": "How to cite ChatGPT\nE.g. APA Style: Cite as software (not as personal communication)."
  },
  {
    "objectID": "slides/presentation-1.html#documentating-ai-use",
    "href": "slides/presentation-1.html#documentating-ai-use",
    "title": "Presentation 1",
    "section": "Documentating AI use",
    "text": "Documentating AI use\n\nSpecifying prompts works well for inexperienced users, but inadequately reflects complex processes.\nExperienced users work with dialogues and several tools, not monolithic prompts in ChatGPT.\nWorking with copilot (code): no traceable prompt input.\nInstead: Document the process, including the tools used and the steps taken.\n\nInclude used tools and steps in appendix, with optional graphical representation.\nServes both evaluation and self-reflection.\n\nIs documentation meaningful in the long term, once the use of AI-based tools has become commonplace?"
  },
  {
    "objectID": "slides/presentation-1.html#detecting-ai-use",
    "href": "slides/presentation-1.html#detecting-ai-use",
    "title": "Presentation 1",
    "section": "Detecting AI use",
    "text": "Detecting AI use\n\nCan be detected by the use of specific vocabulary and phrases: “delve”, “vibrant”, “embark”, “it’s important to note”, ” based on the data provided”.\nDetection tools are not very useful, and can be easily circumvented.\nAccording to Fleckenstein et al. (2024)\n\nGenerative AI can write papers that are undetectable.\nTeachers overestimate their detection abilities."
  }
]