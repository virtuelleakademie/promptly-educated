[
  {
    "objectID": "pages/workshop.html",
    "href": "pages/workshop.html",
    "title": "Using AI in Education: Intermediate",
    "section": "",
    "text": "Pre-Workshop Setup\n\n\n\n\n\nIn this workshop, I recommend working with the following chatbots:\n\n\n\nChatbot\nDescription\nFeatures\n\n\n\n\nClaude\nConsidered by many to be using the best LLMs for a variety of tasks, such as coding and general-purpose writing.\nArtifacts (output in a single document), displays HTML, upload files\n\n\nChatGPT\nThe most popular chatbot, generally good for coding and writing. Its latest models are claimed to perform very well on reasoning tasks.\nWeb access, GPTs, Python code execution, Canvas, upload files\n\n\nHuggingChat\nA chatbot that allows you to use a variety of different open-source LLMs, such as those based on Llama. It’s free, but you need to create an account.\nWeb search, Calculator, Assistants\n\n\n\n\n\nYou will need to create an account on each of these platforms. For Claude and ChatGPT, you will have to use your mobile number to verify your account.\n\n\n\n\nOfficial Claude Documentation\nChatGPT Documentation\nHuggingFace Documentation"
  },
  {
    "objectID": "pages/workshop.html#preparation",
    "href": "pages/workshop.html#preparation",
    "title": "Using AI in Education: Intermediate",
    "section": "",
    "text": "You will need to create an account on each of these platforms. For Claude and ChatGPT, you will have to use your mobile number to verify your account."
  },
  {
    "objectID": "pages/workshop.html#additional-resources",
    "href": "pages/workshop.html#additional-resources",
    "title": "Using AI in Education: Intermediate",
    "section": "",
    "text": "Official Claude Documentation\nChatGPT Documentation\nHuggingFace Documentation"
  },
  {
    "objectID": "pages/workshop.html#session-overview",
    "href": "pages/workshop.html#session-overview",
    "title": "Using AI in Education: Intermediate",
    "section": "Session Overview",
    "text": "Session Overview\n\nOpening Block (15 min)\nFoundations Block (45 min)\nBreak (15 min)\nIntermediate Block (45 min)\nImplementation Block (20 min)\nClosing Block (30 min)"
  },
  {
    "objectID": "pages/workshop.html#opening-activity-the-wolf-goat-and-cabbage-problem-10-min",
    "href": "pages/workshop.html#opening-activity-the-wolf-goat-and-cabbage-problem-10-min",
    "title": "Using AI in Education: Intermediate",
    "section": "Opening Activity: The Wolf, Goat, and Cabbage Problem (10 min)",
    "text": "Opening Activity: The Wolf, Goat, and Cabbage Problem (10 min)\n\n\n\n\n\n\nHands-On Practice\n\n\n\nEnter the following prompt:\nA farmer needs to transport a wolf, a goat, and a cabbage across a river using a small boat. The boat can carry only the farmer and one other item (either the wolf, the goat, or the cabbage) at a time. However, if left together without the farmer’s supervision: The wolf will eat the goat, and the goat will eat the cabbage. The challenge is to figure out how the farmer can get all three items across the river safely.\n\n\n\n\n\n\n\n\nIndividual Practice\n\n\n\n\nCan you solve this task?\nCan the LLM solve this task?\nIf not, why not?\n\n\n\n\n\n\n\n\n\nIn pairs\n\n\n\n\nDiscuss the output of the LLM\nShare your thoughts\n\n\n\n\n\n\n\n\n\nIn groups\n\n\n\n\nBased on your current knowledge of LLMs, what do you think is the problem?\nHow could we modify the task description to make it easier for the LLM?\nWhat does this say about the capabilities of LLMs?"
  },
  {
    "objectID": "pages/workshop.html#understanding-large-language-models-llms",
    "href": "pages/workshop.html#understanding-large-language-models-llms",
    "title": "Using AI in Education: Intermediate",
    "section": "Understanding Large Language Models (LLMs)",
    "text": "Understanding Large Language Models (LLMs)\n    View slides in full screen"
  },
  {
    "objectID": "pages/workshop.html#prompt-engineering-basics",
    "href": "pages/workshop.html#prompt-engineering-basics",
    "title": "Using AI in Education: Intermediate",
    "section": "Prompt Engineering Basics",
    "text": "Prompt Engineering Basics\n    View slides in full screen"
  },
  {
    "objectID": "pages/workshop.html#progressive-revelation-activity",
    "href": "pages/workshop.html#progressive-revelation-activity",
    "title": "Using AI in Education: Intermediate",
    "section": "Progressive Revelation Activity",
    "text": "Progressive Revelation Activity\n\n\n\n\n\n\nHands-On Practice\n\n\n\nProgressive Revelation Activity (15 min)\nStep-by-step prompt building:\n\nStart with basic prompt\nAdd role specification\nAdd context details\nAdd output formatting\nCompare results at each stage\n\n\n\n\n\n\n\n\n\nStep 1: Start with a basic prompt\n\n\n\n\n\nStep 1: Start with a basic prompt\nPrompt: Write a short story about a person who finds a magic lamp.\n\n\n\n\n\n\n\n\n\nStep 2: Add role specification\n\n\n\n\n\nStep 2: Add role specification\nPrompt: You are a professional fiction writer. Write a short story about a person who finds a magic lamp.\n\n\n\n\n\n\n\n\n\nStep 3: Add context details\n\n\n\n\n\nStep 3: Add context details\nPrompt: You are a professional fiction writer. Write a short story (around 300 words) about a young woman named Sarah who finds an old, tarnished magic lamp while cleaning out her grandmother’s attic. The story should be set in a modern, urban setting.\n\n\n\n\n\n\n\n\n\nStep 4: Add output formatting\n\n\n\n\n\nStep 4: Add output formatting\nPrompt: You are a professional fiction writer. Write a short story (around 300 words) about a young woman named Sarah who finds an old, tarnished magic lamp while cleaning out her grandmother’s attic. The story should be set in a modern, urban setting. Format your response using Markdown, with a title and proper paragraphs.\n\n\n\n\n\n\n\n\n\nStep 5: Compare results at each stage\n\n\n\n\n\nStep 5: Compare results at each stage\n\nHow does the output change at each stage?\nWhat effect does each change have?\n\n\n\n\n\n\n\n\n\n\nIn pairs\n\n\n\n\nShare your thoughts with your neighbour"
  },
  {
    "objectID": "pages/workshop.html#progressive-revelation-activity-15-min",
    "href": "pages/workshop.html#progressive-revelation-activity-15-min",
    "title": "Using AI in Education: Intermediate",
    "section": "Progressive Revelation Activity (15 min)",
    "text": "Progressive Revelation Activity (15 min)\nStep-by-step prompt building:\n\nStart with basic prompt\nAdd role specification\nAdd context details\nAdd output formatting\nCompare results at each stage"
  },
  {
    "objectID": "pages/workshop.html#step-1-start-with-a-basic-prompt",
    "href": "pages/workshop.html#step-1-start-with-a-basic-prompt",
    "title": "Using AI in Education: Intermediate",
    "section": "Step 1: Start with a basic prompt",
    "text": "Step 1: Start with a basic prompt\nPrompt: Write a short story about a person who finds a magic lamp."
  },
  {
    "objectID": "pages/workshop.html#step-2-add-role-specification",
    "href": "pages/workshop.html#step-2-add-role-specification",
    "title": "Using AI in Education: Intermediate",
    "section": "Step 2: Add role specification",
    "text": "Step 2: Add role specification\nPrompt: You are a professional fiction writer. Write a short story about a person who finds a magic lamp."
  },
  {
    "objectID": "pages/workshop.html#step-3-add-context-details",
    "href": "pages/workshop.html#step-3-add-context-details",
    "title": "Using AI in Education: Intermediate",
    "section": "Step 3: Add context details",
    "text": "Step 3: Add context details\nPrompt: You are a professional fiction writer. Write a short story (around 300 words) about a young woman named Sarah who finds an old, tarnished magic lamp while cleaning out her grandmother’s attic. The story should be set in a modern, urban setting."
  },
  {
    "objectID": "pages/workshop.html#step-4-add-output-formatting",
    "href": "pages/workshop.html#step-4-add-output-formatting",
    "title": "Using AI in Education: Intermediate",
    "section": "Step 4: Add output formatting",
    "text": "Step 4: Add output formatting\nPrompt: You are a professional fiction writer. Write a short story (around 300 words) about a young woman named Sarah who finds an old, tarnished magic lamp while cleaning out her grandmother’s attic. The story should be set in a modern, urban setting. Format your response using Markdown, with a title and proper paragraphs."
  },
  {
    "objectID": "pages/workshop.html#step-5-compare-results-at-each-stage",
    "href": "pages/workshop.html#step-5-compare-results-at-each-stage",
    "title": "Using AI in Education: Intermediate",
    "section": "Step 5: Compare results at each stage",
    "text": "Step 5: Compare results at each stage\n\nHow does the output change at each stage?\nWhat effect does each change have?"
  },
  {
    "objectID": "pages/workshop.html#prompt-reverse-engineering-exercise",
    "href": "pages/workshop.html#prompt-reverse-engineering-exercise",
    "title": "Using AI in Education: Intermediate",
    "section": "Prompt Reverse-Engineering Exercise",
    "text": "Prompt Reverse-Engineering Exercise\n\n\n\n\n\n\nPrompt Detective Exercise (15 min)\n\n\n\n\n\nExamine the outputs below and try to reconstruct the prompt that could have generated it.\nTest your prompt with the LLM and compare the output to the original.\n\n\n\n\nOutput 1:\n\n\n\nElement\nSymbol\nAtomic Number\nAtomic Mass\n\n\n\n\nHydrogen\nH\n1\n1.008\n\n\nHelium\nHe\n2\n4.003\n\n\nLithium\nLi\n3\n6.941\n\n\nBeryllium\nBe\n4\n9.012\n\n\nBoron\nB\n5\n10.811\n\n\nCarbon\nC\n6\n12.011\n\n\n\n:::\n\n\nOutput 2:\n\n\n\n\n\n\n\n\nGreek Letter\nPronunciation\nExample Usage\n\n\n\n\nα (alpha)\nal-fah\nUsed to represent the first letter of the Greek alphabet, or the first in a series.\n\n\nβ (beta)\nbay-tah\nUsed in mathematics and science to represent various constants or coefficients.\n\n\nγ (gamma)\ngam-ah\nUsed in physics to represent the ratio of two quantities, or in mathematics as a function.\n\n\nδ (delta)\ndel-tah\nUsed to represent a change or difference in a quantity, or as a symbol for a small increment.\n\n\nε (epsilon)\nep-si-lon\nUsed in mathematics to represent a small positive number, or in engineering to represent strain.\n\n\nπ (pi)\npie\nUsed to represent the ratio of a circle’s circumference to its diameter, a fundamental constant in mathematics.\n\n\n\n:::\n\n\n\n\n\n\nPrompt Detective Exercise (15 min)\n\n\n\nYour Task:\n\nDiscuss with your group:\n\nWhat elements did you include in your prompt?\nHow did your output differ from the original?\nWhat changes could you make to your prompt to better match the desired output?"
  },
  {
    "objectID": "pages/workshop.html#coffee-break",
    "href": "pages/workshop.html#coffee-break",
    "title": "Using AI in Education: Intermediate",
    "section": "Coffee Break",
    "text": "Coffee Break\n\nTechnical support available"
  },
  {
    "objectID": "pages/workshop.html#prompt-engineering-intermediate-techniques",
    "href": "pages/workshop.html#prompt-engineering-intermediate-techniques",
    "title": "Using AI in Education: Intermediate",
    "section": "Prompt Engineering Intermediate Techniques",
    "text": "Prompt Engineering Intermediate Techniques\n    View slides in full screen"
  },
  {
    "objectID": "pages/workshop.html#error-first-learning-activity",
    "href": "pages/workshop.html#error-first-learning-activity",
    "title": "Using AI in Education: Intermediate",
    "section": "Error-First Learning Activity",
    "text": "Error-First Learning Activity\n\n\n\n\n\n\nLearning from Mistakes\n\n\n\nError-First Learning Activity (20 min)\nUpload a research paper (ChatGPT or Claude)\n\n\n\n\n\n\nVague instructions\n\n\n\n\n\nWrite a summary of the following research paper.\n\n\n\n\n\n\n\n\n\nPotential improvements\n\n\n\n\n\nPotential improvements:\n\nSpecify what should be summarized (e.g. a book, article, etc.)\nProvide context about the topic or content\nGive guidance on the desired length or format of the summary\n\n\n\n\n\n\n\n\n\n\nMissing Context\n\n\n\n\n\nPrompt: Explain the concept of “machine learning” to an audience.\n\n\n\n\n\n\n\n\n\nPotential improvements\n\n\n\n\n\nPotential improvements:\n\nBackground information about the audience (e.g. technical expertise, age group, etc.)\nDesired level of technical depth or terminology\nExpected length or format of the explanation\n\n\n\n\n\n\n\n\n\n\nPoor Formatting\n\n\n\n\n\nPrompt: Provide a table with information about the first 10 elements of the periodic table, including their symbols, atomic numbers, and atomic masses.\n\n\n\n\n\n\n\n\n\nPotential improvements\n\n\n\n\n\nPotential improvements:\n\nSpecify the desired output format (e.g. table, bullet points, etc.)\nClarify the order and arrangement of information\nIndicate any additional details needed (e.g. units, descriptions, etc.)\n\n\n\n\n\n\n\n\n\n\nIndividual Practice\n\n\n\n\nAttempt fixes\n\n\n\n\n\n\n\n\n\nDiscuss fixes\n\n\n\n\nDiscuss fixes with your group"
  },
  {
    "objectID": "pages/workshop.html#prompt-surgery-workshop",
    "href": "pages/workshop.html#prompt-surgery-workshop",
    "title": "Using AI in Education: Intermediate",
    "section": "Prompt Surgery Workshop",
    "text": "Prompt Surgery Workshop\n\n\n\n\n\n\nCollaborative Analysis\n\n\n\nReducing hallucinations (10 min)\n\nExamine problematic prompt\nDiagnose issues\nApply fixes\nTest and refine\nShare successful strategies\n\n\n\n\n\n\n\n\n\nSummarize research\n\n\n\n\n\nPrompt: Summarize key findings on the development of metacognition and self-regulated learning strategies in children.\n\n\n\n\n\n\n\n\n\nOutput\n\n\n\n\n\nKey Findings on the Development of Metacognition and Self-Regulated Learning (SRL) Strategies in Children\n\n1. Emergence of Metacognition\n\nEarly Development: Metacognitive skills, such as the ability to monitor one’s own thinking and regulate learning, begin to emerge in early childhood. Children as young as 3-5 years old show some capacity for metacognitive thinking, though it is rudimentary.\nGrowth During School Years: Between ages 7 and 12, children significantly improve their metacognitive skills, particularly their ability to reflect on their thinking and adjust learning strategies. This period marks the transition from implicit, intuitive metacognition to more explicit forms.\nContinued Development into Adolescence: Adolescents show greater sophistication in planning, monitoring, and evaluating their learning, reflecting the continued maturation of executive functions and cognitive control.\n\n\n\n2. Components of Self-Regulated Learning\n\nPlanning: The ability to set goals and plan learning strategies develops with age. Young children often need external guidance, but by late elementary school, they begin to adopt more autonomous strategies for planning their work.\nMonitoring and Evaluation: Young children struggle to accurately monitor their learning progress, often overestimating their understanding or skills. As they grow older, they become more accurate in assessing their learning, which is crucial for self-correction and improvement.\nControl of Learning Strategies: Children initially rely on simple strategies, such as repetition. Over time, they learn to apply more sophisticated strategies (e.g., elaboration, summarization), and they become more flexible in selecting strategies suited to different tasks.\n\n\n\n3. Influences on Development\n\nCognitive Maturity: The development of executive functions, such as working memory and cognitive flexibility, plays a vital role in enhancing metacognition and self-regulated learning skills.\nSocial and Environmental Factors: Teachers, parents, and peers provide models and feedback that shape children’s development of metacognitive and SRL strategies. Scaffolding and direct instruction from adults are especially helpful in the early stages.\nTask Complexity and Experience: Exposure to a variety of tasks, particularly those that challenge children’s cognitive limits, fosters the development of metacognitive strategies. Success in tasks requiring problem-solving or critical thinking accelerates metacognitive growth.\n\n\n\n4. Challenges in Metacognitive Development\n\nOverconfidence: Younger children often exhibit overconfidence in their abilities, underestimating the difficulty of tasks and overestimating their understanding. This diminishes as they gain more experience and feedback.\nTransfer of Skills: While children may develop metacognitive strategies in specific contexts, transferring these skills to new, unfamiliar situations can be difficult. Explicit teaching and practice in various contexts enhance transferability.\n\n\n\n5. Educational Implications\n\nInstructional Approaches: Instruction that encourages reflection, self-assessment, and the explicit teaching of learning strategies can accelerate metacognitive and SRL development. For example, teaching students how to set goals, self-monitor, and adjust strategies based on feedback improves their learning outcomes.\nRole of Feedback: Timely and specific feedback helps children refine their self-assessment skills and encourages them to adjust their learning strategies more effectively.\nTechnology and Tools: Digital tools and adaptive learning platforms that provide real-time feedback and promote self-reflection can be particularly effective in helping children develop metacognitive and SRL skills.\n\nIn summary, the development of metacognition and self-regulated learning strategies is a gradual process that builds on both cognitive maturation and experience. With proper guidance and instruction, children become increasingly capable of managing and directing their own learning effectively.\n\n\n\n\n\n\n\n\n\n\nPotential improvements\n\n\n\n\n\nStrategies to reduce hallucination include:\n\nProviding relevant factual context from trusted sources.\nInstructing the LLM to admit when it lacks knowledge about a topic.\n\nThe key is to carefully craft prompts and contexts that guide the LLM towards factual responses and away from hallucinating or making up information."
  },
  {
    "objectID": "pages/workshop.html#emergence-of-metacognition",
    "href": "pages/workshop.html#emergence-of-metacognition",
    "title": "Using AI in Education: Intermediate",
    "section": "1. Emergence of Metacognition",
    "text": "1. Emergence of Metacognition\n\nEarly Development: Metacognitive skills, such as the ability to monitor one’s own thinking and regulate learning, begin to emerge in early childhood. Children as young as 3-5 years old show some capacity for metacognitive thinking, though it is rudimentary.\nGrowth During School Years: Between ages 7 and 12, children significantly improve their metacognitive skills, particularly their ability to reflect on their thinking and adjust learning strategies. This period marks the transition from implicit, intuitive metacognition to more explicit forms.\nContinued Development into Adolescence: Adolescents show greater sophistication in planning, monitoring, and evaluating their learning, reflecting the continued maturation of executive functions and cognitive control."
  },
  {
    "objectID": "pages/workshop.html#components-of-self-regulated-learning",
    "href": "pages/workshop.html#components-of-self-regulated-learning",
    "title": "Using AI in Education: Intermediate",
    "section": "2. Components of Self-Regulated Learning",
    "text": "2. Components of Self-Regulated Learning\n\nPlanning: The ability to set goals and plan learning strategies develops with age. Young children often need external guidance, but by late elementary school, they begin to adopt more autonomous strategies for planning their work.\nMonitoring and Evaluation: Young children struggle to accurately monitor their learning progress, often overestimating their understanding or skills. As they grow older, they become more accurate in assessing their learning, which is crucial for self-correction and improvement.\nControl of Learning Strategies: Children initially rely on simple strategies, such as repetition. Over time, they learn to apply more sophisticated strategies (e.g., elaboration, summarization), and they become more flexible in selecting strategies suited to different tasks."
  },
  {
    "objectID": "pages/workshop.html#influences-on-development",
    "href": "pages/workshop.html#influences-on-development",
    "title": "Using AI in Education: Intermediate",
    "section": "3. Influences on Development",
    "text": "3. Influences on Development\n\nCognitive Maturity: The development of executive functions, such as working memory and cognitive flexibility, plays a vital role in enhancing metacognition and self-regulated learning skills.\nSocial and Environmental Factors: Teachers, parents, and peers provide models and feedback that shape children’s development of metacognitive and SRL strategies. Scaffolding and direct instruction from adults are especially helpful in the early stages.\nTask Complexity and Experience: Exposure to a variety of tasks, particularly those that challenge children’s cognitive limits, fosters the development of metacognitive strategies. Success in tasks requiring problem-solving or critical thinking accelerates metacognitive growth."
  },
  {
    "objectID": "pages/workshop.html#challenges-in-metacognitive-development",
    "href": "pages/workshop.html#challenges-in-metacognitive-development",
    "title": "Using AI in Education: Intermediate",
    "section": "4. Challenges in Metacognitive Development",
    "text": "4. Challenges in Metacognitive Development\n\nOverconfidence: Younger children often exhibit overconfidence in their abilities, underestimating the difficulty of tasks and overestimating their understanding. This diminishes as they gain more experience and feedback.\nTransfer of Skills: While children may develop metacognitive strategies in specific contexts, transferring these skills to new, unfamiliar situations can be difficult. Explicit teaching and practice in various contexts enhance transferability."
  },
  {
    "objectID": "pages/workshop.html#educational-implications",
    "href": "pages/workshop.html#educational-implications",
    "title": "Using AI in Education: Intermediate",
    "section": "5. Educational Implications",
    "text": "5. Educational Implications\n\nInstructional Approaches: Instruction that encourages reflection, self-assessment, and the explicit teaching of learning strategies can accelerate metacognitive and SRL development. For example, teaching students how to set goals, self-monitor, and adjust strategies based on feedback improves their learning outcomes.\nRole of Feedback: Timely and specific feedback helps children refine their self-assessment skills and encourages them to adjust their learning strategies more effectively.\nTechnology and Tools: Digital tools and adaptive learning platforms that provide real-time feedback and promote self-reflection can be particularly effective in helping children develop metacognitive and SRL skills.\n\nIn summary, the development of metacognition and self-regulated learning strategies is a gradual process that builds on both cognitive maturation and experience. With proper guidance and instruction, children become increasingly capable of managing and directing their own learning effectively."
  },
  {
    "objectID": "pages/workshop.html#anki-flashcard-project",
    "href": "pages/workshop.html#anki-flashcard-project",
    "title": "Using AI in Education: Intermediate",
    "section": "Anki Flashcard Project",
    "text": "Anki Flashcard Project\n[Anki](https://apps.ankiweb.net/ is a powerful open-source flashcard program that uses the principles of spaced repetition and active recall to enhance learning and long-term retention. It presents flashcards at optimal intervals, adjusting the frequency of review based on the user’s performance. This is thought to ensure that information is reinforced before it is forgotten.\nOne of the key strengths of Anki is its flexibility. Users can create their own decks of flashcards tailored to their specific learning needs, or they can download pre-made decks from shared repositories covering a vast array of subjects, from languages and vocabulary to complex medical terminology.\nHowever, Anki requires a lot of manual work to create effective flashcards. In this workshop, we will use an LLM to generate the flashcards for us.\n\n\n\n\n\n\nAnki Flashcard Project\n\n\n\n\n\nThe simplest type of Anki flashcard is a pair of text fields: a question and an answer (or a term and a definition).\nAnki can import flashcards in a variety of formats, including Anki’s native format, but also from a comma-separated values (CSV) file.\nA CSV file is a text file that uses a comma to separate values. Each line of the file is a row, and each row has of one or more columns, separated by commas.\nIf we have the following list of terms and definitions:\n\n\n\n\n\n\n\nterm\ndefinition\n\n\n\n\nMetacognition\n“The ability to think about one’s own thinking processes”\n\n\nSelf-Regulated Learning\n“The process of taking control of and evaluating one’s own learning”\n\n\nExecutive Functions\n“Higher-order cognitive processes like working memory and cognitive flexibility”\n\n\nScaffolding\n“Support provided by teachers or peers to help students learn new skills”\n\n\n\nwe can save these in a CSV file like this:\nterm,definition\nMetacognition,\"The ability to think about one's own thinking processes\"\nSelf-Regulated Learning,\"The process of taking control of and evaluating one's own learning\"\nExecutive Functions,\"Higher-order cognitive processes like working memory and cognitive flexibility\"\nScaffolding,\"Support provided by teachers or peers to help students learn new skills\"\nIf we save the contents above in a file called anki-flashcards.csv, we can import them into Anki by selecting the `File -&gt; Import… menu item.\n\n\n\n\n\n\n\n\n\nGoal\n\n\n\nThe goal of this project is to create a set of flashcards based on your teaching material, and to save these in a CSV file that can be imported into Anki.\n\n\n\n\n\n\n\n\nProject Work\n\n\n\nAnki Flashcard Project - Phase 1 (10 min)\n\nSelect teaching material\nApply learned prompting techniques\nCreate initial flashcard prompt\nTest and document results\n\n\n\n\n\n\n\n\n\nPeer Review\n\n\n\nGroup Refinement - Phase 2 (10 min)\n\nForm groups of 3-4\nShare and test prompts\nPeer review using checklist\nRefine based on feedback\n\n\n\n\n\n\n\n\n\nOptional\n\n\n\n\n\nExport Phase - Phase 3 (10 min)\n\nInstall Anki\nTest import process\nTroubleshoot issues"
  },
  {
    "objectID": "pages/workshop.html#optional-ai-and-learning-environments",
    "href": "pages/workshop.html#optional-ai-and-learning-environments",
    "title": "Using AI in Education: Intermediate",
    "section": "Optional AI and learning environments",
    "text": "Optional AI and learning environments\n    View slides in full screen"
  },
  {
    "objectID": "pages/workshop.html#final-wrap-up",
    "href": "pages/workshop.html#final-wrap-up",
    "title": "Using AI in Education: Intermediate",
    "section": "Final Wrap-Up",
    "text": "Final Wrap-Up\n\n\n\n\n\n\nWrap-Up\n\n\n\nFinal Review (5 min)\n\nKey takeaways\nNext steps"
  },
  {
    "objectID": "slides/llms-in-education.html#what-is-artifical-intelligence",
    "href": "slides/llms-in-education.html#what-is-artifical-intelligence",
    "title": "Large Langauge Models in Education",
    "section": "What is Artifical Intelligence?",
    "text": "What is Artifical Intelligence?\n\n\n\n\nA branch of computer science that aims to create machines that can perform tasks that typically require human intelligence."
  },
  {
    "objectID": "slides/llms-in-education.html#what-is-a-large-language-model",
    "href": "slides/llms-in-education.html#what-is-a-large-language-model",
    "title": "Large Langauge Models in Education",
    "section": "What is a Large Language Model?",
    "text": "What is a Large Language Model?\n\n\n\n\nAn LLM is a type of generative AI model that is trained to predict the next word following the input (prompt)."
  },
  {
    "objectID": "slides/llms-in-education.html#how-to-train-a-language-model",
    "href": "slides/llms-in-education.html#how-to-train-a-language-model",
    "title": "Large Langauge Models in Education",
    "section": "How to train a language model",
    "text": "How to train a language model\n\nAn LLM learns to predict the next word in a sequence, given the previous words: \\[ P(word | context) \\]\nThink of as “fancy autocomplete” (but very very powerful and sopisticated)"
  },
  {
    "objectID": "slides/llms-in-education.html#how-does-an-llm-generate-text",
    "href": "slides/llms-in-education.html#how-does-an-llm-generate-text",
    "title": "Large Langauge Models in Education",
    "section": "How does an LLM generate text?",
    "text": "How does an LLM generate text?"
  },
  {
    "objectID": "slides/llms-in-education.html#sampling",
    "href": "slides/llms-in-education.html#sampling",
    "title": "Large Langauge Models in Education",
    "section": "Sampling",
    "text": "Sampling"
  },
  {
    "objectID": "slides/llms-in-education.html#auto-regressive-generation",
    "href": "slides/llms-in-education.html#auto-regressive-generation",
    "title": "Large Langauge Models in Education",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation\nText is generated one word at a time (actually tokens, not words).\n\n\n\n\n\n Generated text depends on the generative model and the context.\n Every word (token) is given an equal amount time (computation per token is constant)."
  },
  {
    "objectID": "slides/llms-in-education.html#auto-regressive-generation-1",
    "href": "slides/llms-in-education.html#auto-regressive-generation-1",
    "title": "Large Langauge Models in Education",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation"
  },
  {
    "objectID": "slides/llms-in-education.html#foundation-models",
    "href": "slides/llms-in-education.html#foundation-models",
    "title": "Large Langauge Models in Education",
    "section": "Foundation models",
    "text": "Foundation models\nA foundation model, or large language model (LLM):\n\nis a type of machine learning model that is trained to predict the next word following the input (prompt).\nis trained “simply” to predict the next word following a sequence of words.\ndoes not necessarily produce human-like conversations.\n\n\n\n\n: What is the capital of France?\n: What is the capital of Germany? What is the capital of Italy? . .."
  },
  {
    "objectID": "slides/llms-in-education.html#training-process",
    "href": "slides/llms-in-education.html#training-process",
    "title": "Large Langauge Models in Education",
    "section": "Training process",
    "text": "Training process\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/llms-in-education.html#assistant-models",
    "href": "slides/llms-in-education.html#assistant-models",
    "title": "Large Langauge Models in Education",
    "section": "Assistant models",
    "text": "Assistant models\nTrained (fine-tuned) to have conversations: turn-taking, question answering, not being rude/sexist/racist.\n\n\n\n\n\n\nFoundation model has learned to predict all kinds of text, including both desirable and undesirable text.\nFine-tuning narrows down the space of all possible output to only desirable, human-like dialogue.\nModel is aligned with the values of the fine-tuner."
  },
  {
    "objectID": "slides/llms-in-education.html#how-do-chatbots-work",
    "href": "slides/llms-in-education.html#how-do-chatbots-work",
    "title": "Large Langauge Models in Education",
    "section": "How do Chatbots work?",
    "text": "How do Chatbots work?\n\n\nDesigned to present the illusion of a conversation between two entities."
  },
  {
    "objectID": "slides/llms-in-education.html#how-do-chatbots-actually-work",
    "href": "slides/llms-in-education.html#how-do-chatbots-actually-work",
    "title": "Large Langauge Models in Education",
    "section": "How do chatbots actually work?",
    "text": "How do chatbots actually work?"
  },
  {
    "objectID": "slides/llms-in-education.html#an-assistant-model-is-a-conversation-simulator",
    "href": "slides/llms-in-education.html#an-assistant-model-is-a-conversation-simulator",
    "title": "Large Langauge Models in Education",
    "section": "An assistant model is a conversation simulator",
    "text": "An assistant model is a conversation simulator\n\n\n\n\n\nAn assistant is trained to respond to user prompts in a human-like way.\nSimulates possible human conversations.\nHas no intentions. It is not an entity with its own goals.\nDoes not have a “personality” or “character” in the traditional sense. It can be thought of as a role-playing simulator.\nHas no concept of “truth” or “lying”. The model is not trying to deceive the user, it is simply trying to respond in a human-like way."
  },
  {
    "objectID": "slides/llms-in-education.html#capabilities-and-limitations",
    "href": "slides/llms-in-education.html#capabilities-and-limitations",
    "title": "Large Langauge Models in Education",
    "section": "Capabilities and limitations",
    "text": "Capabilities and limitations\n\n\nWhat are LLMs good at?\n\nFixing grammar, bad writing, etc.\nRephrasing\nAnalyzing texts\nWriting computer code\nAnswering questions about a knowledge base\nTranslating languages\nCreating structured output\nFactual output with external documents or web search\n\n\nLimitations\n\nThey make stuff up (hallucinate)\nThey learn biases from the training data\nWeird vocabulary, e.g. delve\n(Chatbots have privacy issues)"
  },
  {
    "objectID": "slides/llms-in-education.html#hallucination",
    "href": "slides/llms-in-education.html#hallucination",
    "title": "Large Langauge Models in Education",
    "section": "Hallucination",
    "text": "Hallucination\n\n\n\n\n\nLLMs can generate text that is not true, or not based on any real-world knowledge.\nThis is known as “hallucination”. A better term would be “confabulation”."
  },
  {
    "objectID": "slides/llms-in-education.html#can-an-llm-tell-the-truth",
    "href": "slides/llms-in-education.html#can-an-llm-tell-the-truth",
    "title": "Large Langauge Models in Education",
    "section": "Can an LLM tell the truth?",
    "text": "Can an LLM tell the truth?\n\nHow would you know if an LLM is able to give you factual information?\nHow would you test this?\n\n\n\n\n: What is the capital of Uzbekistan?\n: Tashkent\n\n\n\nIt looks like the LLM knows the capital of Uzbekistan1.\nWhat it is actually doing is responding with the most likely sequence following the question."
  },
  {
    "objectID": "slides/llms-in-education.html#knowledge-base",
    "href": "slides/llms-in-education.html#knowledge-base",
    "title": "Large Langauge Models in Education",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\nA knowledge base is a collection of facts about the world.\n\nYou can ask (retrieve) and tell (store) facts.\n\nAn LLM is not a knowledge base.\n\nLLMs generate text based on on how probable the next word is given the context, not based on stored facts."
  },
  {
    "objectID": "slides/llms-in-education.html#biases",
    "href": "slides/llms-in-education.html#biases",
    "title": "Large Langauge Models in Education",
    "section": "Biases",
    "text": "Biases\n\n\n\n\n\n\n\n\nBiases in LLMs\nSource\nExamples\n\n\n\n\nTraining data bias\nText from internet, books, articles.\nStereotypes reflecting gender, race, religion.\n\n\nRepresentation bias\nUnderrepresented groups/perspectives in data.\nLess accurate responses for minority cultures.\n\n\nAlgorithmic bias\nTraining and fine-tuning algorithms.\nOptimizations for fluency and coherence may lead to preference for dominant cultural narratives.\n\n\nUser interaction bias\nAdaptation based on user interactions.\nIncreased biased or harmful content generation."
  },
  {
    "objectID": "slides/llms-in-education.html#privacy-concerns",
    "href": "slides/llms-in-education.html#privacy-concerns",
    "title": "Large Langauge Models in Education",
    "section": "Privacy concerns",
    "text": "Privacy concerns\n\n\n\n\n\n\n\n\nPrivacy Concerns\nIssue\nExamples\n\n\n\n\nData memorization\nMemorizing sensitive information.\nReproducing phone numbers, addresses.\n\n\nTraining data leakage\nUnauthorized dissemination of confidential data.\nSummarizing proprietary documents.\n\n\nUser query logging\nStoring sensitive user interactions.\nExposing private queries if data is mishandled.\n\n\nQueries used for training\nUser queries may be used for further training.\nPersonal data in queries could be inadvertently included in training data."
  },
  {
    "objectID": "slides/llms-in-education.html#prompting",
    "href": "slides/llms-in-education.html#prompting",
    "title": "Large Langauge Models in Education",
    "section": "Prompting",
    "text": "Prompting"
  },
  {
    "objectID": "slides/llms-in-education.html#what-is-a-prompt",
    "href": "slides/llms-in-education.html#what-is-a-prompt",
    "title": "Large Langauge Models in Education",
    "section": "What is a prompt?",
    "text": "What is a prompt?\n\nAn LLM’s task is to complete text.\nA prompt is a piece of text (instruction) that is given to a language model to complete.\n\n\n\n\nPROMPT : Write a haiku about a workshop on large language models.\nASSISTANT : Whispers of circuits,\nKnowledge blooms in bytes and bits,\nModel learns and fits.\n\n\n\n\nThe response is generated as continuation of, and conditioned on, the prompt.\n\n\nMore technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt."
  },
  {
    "objectID": "slides/llms-in-education.html#prompt-engineering",
    "href": "slides/llms-in-education.html#prompt-engineering",
    "title": "Large Langauge Models in Education",
    "section": "Prompt engineering",
    "text": "Prompt engineering\n\n\n\n\n\nLLMs learn to do things they were not explicitly trained to do: translation, reasoning, etc. \nOften, these capabilities need to be “unlocked” by the right prompt. \n\n\n\nBut what is the right prompt?\nThe answer is very similar to what you would tell a human dialogue partner/assistant.\nYou can increase the probability of getting the desired output by providing context and examples."
  },
  {
    "objectID": "slides/llms-in-education.html#basics-of-prompting",
    "href": "slides/llms-in-education.html#basics-of-prompting",
    "title": "Large Langauge Models in Education",
    "section": "Basics of prompting",
    "text": "Basics of prompting\nOpenAI give a set of strategies for using their models effectively:\n Prompt engineering\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving the LLM ‘time to think’\nusing external tools"
  },
  {
    "objectID": "slides/llms-in-education.html#writing-clear-instructions",
    "href": "slides/llms-in-education.html#writing-clear-instructions",
    "title": "Large Langauge Models in Education",
    "section": "Writing clear instructions",
    "text": "Writing clear instructions\n\n\n\nInstructions should be clear and unambiguous.\nThink of an LLM as a role-playing conversation simulator: Indicate which role the model (persona) should adopt.\n\n\n\n\n\n\nInclude details in your query to get more relevant answers\nAsk the model to adopt a persona\nUse delimiters to clearly indicate distinct parts of the input\nSpecify the steps required to complete a task\nProvide examples\nSpecify the desired length of the output"
  },
  {
    "objectID": "slides/llms-in-education.html#adopt-a-persona-role",
    "href": "slides/llms-in-education.html#adopt-a-persona-role",
    "title": "Large Langauge Models in Education",
    "section": "Adopt a persona (role)",
    "text": "Adopt a persona (role)\n\n\n\n: You are an expert on learning techniques. Explain the concept of ‘flipped classroom’ in one paragraph.\n\n\n\n\n\n\n: You are an expert financial derivatives. Explain the concept of ‘flipped classroom’ in one paragraph."
  },
  {
    "objectID": "slides/llms-in-education.html#provide-reference-texts",
    "href": "slides/llms-in-education.html#provide-reference-texts",
    "title": "Large Langauge Models in Education",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\nProvide a model with trusted and relevant information.\nThen instruct the model to use the provided information to compose its answer.\n\n Instruct the model to answer using a reference text\n\n\n\nThis can be extended to retrieval-augmented generation (RAG). First create a database of documents, then retrieve the most relevant documents, based on a user’s query. These are then included in the prompt to the model. The model is instructed to use the information in the documents to compose its answer."
  },
  {
    "objectID": "slides/llms-in-education.html#create-structured-output",
    "href": "slides/llms-in-education.html#create-structured-output",
    "title": "Large Langauge Models in Education",
    "section": "Create structured output",
    "text": "Create structured output\n\nExplanation: Instruct the model to generate structured output.\nE.g. provide a table, a list, a diagram, etc.\nUse delimiters to indicate distinct parts of the input.\nExample: Extract information from a text and present it in a table."
  },
  {
    "objectID": "slides/llms-in-education.html#structured-prompting-techniques",
    "href": "slides/llms-in-education.html#structured-prompting-techniques",
    "title": "Large Langauge Models in Education",
    "section": "Structured prompting techniques",
    "text": "Structured prompting techniques\n\nIn-Context Learning: Provide examples within the prompt.\nThought Generation: Instruct the model to think step-by-step.\nDecomposition Techniques: Break down tasks into subtasks.\n\n(Schulhoff et al. 2024)"
  },
  {
    "objectID": "slides/llms-in-education.html#in-context-learning",
    "href": "slides/llms-in-education.html#in-context-learning",
    "title": "Large Langauge Models in Education",
    "section": "In-Context learning",
    "text": "In-Context learning\n\nExplanation: Providing examples or context within the prompt itself.\nFew-shot prompting: Give a few examples.\n\nExample: Translate the following sentences:\n\nEnglish: ‘What time is it?’ -&gt; French: ‘Quelle heure est-il?’\nEnglish: ‘Where is the library?’ -&gt; French:\n\n\nZero-shot prompting: No examples, relies on pre-trained knowledge.\n\nExample: Translate the following sentence…"
  },
  {
    "objectID": "slides/llms-in-education.html#thought-generation",
    "href": "slides/llms-in-education.html#thought-generation",
    "title": "Large Langauge Models in Education",
    "section": "Thought generation",
    "text": "Thought generation\n\nExplanation: Encourages the model to show its reasoning process.\nChain-of-Thought (CoT) prompting: encourages the LLM to “explain” its intermediate reasoning steps.\nCan often be induced by simply instructing the model to think step-by-step or Take a deep breath and work on this problem step-by-step (Yang et al. 2023)."
  },
  {
    "objectID": "slides/llms-in-education.html#chain-of-thought-example",
    "href": "slides/llms-in-education.html#chain-of-thought-example",
    "title": "Large Langauge Models in Education",
    "section": "Chain-of-Thought example",
    "text": "Chain-of-Thought example\nInstead of this:\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Yes or no?\n\n\n\nDo this:\n\n\n\n: Is this statement correct? The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\nReason through the problem step-by-step. Start by identifying the odd numbers. Next, add them up. Finally, determine if the sum is even or odd. Write down your reasoning steps in a numbered list.\n\n\n\n\nWhy does this work?"
  },
  {
    "objectID": "slides/llms-in-education.html#decomposition-techniques",
    "href": "slides/llms-in-education.html#decomposition-techniques",
    "title": "Large Langauge Models in Education",
    "section": "Decomposition techniques",
    "text": "Decomposition techniques\n\nExplanation: Force the LLM to break down complex tasks into manageable subtasks.\nLeast-to-Most Prompting: Start simple, increase complexity.\n\nExample: List items, calculate cost…\n\nPlan-and-Solve Prompting: Separate planning and execution phases.\n\nExample: Understand the problem, devise a plan…"
  },
  {
    "objectID": "slides/llms-in-education.html#hands-on-practice-prompting",
    "href": "slides/llms-in-education.html#hands-on-practice-prompting",
    "title": "Large Langauge Models in Education",
    "section": "Hands-on practice: Prompting",
    "text": "Hands-on practice: Prompting\n\nPractice writing prompts for different tasks ( 20 minutes).\nWrite an essay using an LLM, and then critique someone else’s essay ( 30 minutes).\n\n  If you need further help with prompting techniques, see these websites:\n\n Learn prompting\n Prompting guide\n OpenAI cookbook"
  },
  {
    "objectID": "slides/llms-in-education.html#chatgpt-edu",
    "href": "slides/llms-in-education.html#chatgpt-edu",
    "title": "Large Langauge Models in Education",
    "section": "ChatGPT Edu",
    "text": "ChatGPT Edu\n\n\n \n\n\n\n\nAccess to GPT-4o, excelling in text interpretation, coding, and mathematics\nData analytics, web browsing, and document summarization\nBuild GPTs, custom versions of ChatGPT, and share them within university workspaces\nSignificantly higher message limits than the free version of ChatGPT\nImproved language capabilities across quality and speed, with over 50 languages supported\nRobust security, data privacy, and administrative controls\nConversations and data are not used to train OpenAI models"
  },
  {
    "objectID": "slides/llms-in-education.html#gpts",
    "href": "slides/llms-in-education.html#gpts",
    "title": "Large Langauge Models in Education",
    "section": "GPTs",
    "text": "GPTs"
  },
  {
    "objectID": "slides/llms-in-education.html#hands-on-practice-gpts",
    "href": "slides/llms-in-education.html#hands-on-practice-gpts",
    "title": "Large Langauge Models in Education",
    "section": "Hands-on practice: GPTs",
    "text": "Hands-on practice: GPTs\n\nTry out custom GPTs from various categories in the GPT store.\nDiscuss with your neighbour\n\nDid you discover any useful GPTs?\nWhat are the benefits and limitations of using GPTs in the classroom?"
  },
  {
    "objectID": "slides/llms-in-education.html#extended-cognition",
    "href": "slides/llms-in-education.html#extended-cognition",
    "title": "Large Langauge Models in Education",
    "section": "Extended cognition",
    "text": "Extended cognition\n\n\n\nAccording to Clark and Chalmers (1998), cognitive processes may extend to external objects.\nKrakauer (2016) distinguishes between complementary and competitive cognitive artifacts.\n\nComplementary: numbers, abacus\nCompetetive: calculator, GPS\n\nWhat kind of artefact will AI turn out to be?"
  },
  {
    "objectID": "slides/llms-in-education.html#deskilling-vs.-upskilling",
    "href": "slides/llms-in-education.html#deskilling-vs.-upskilling",
    "title": "Large Langauge Models in Education",
    "section": "Deskilling vs. upskilling",
    "text": "Deskilling vs. upskilling"
  },
  {
    "objectID": "slides/llms-in-education.html#writing-tasks-in-the-ai-era",
    "href": "slides/llms-in-education.html#writing-tasks-in-the-ai-era",
    "title": "Large Langauge Models in Education",
    "section": "Writing tasks in the AI era",
    "text": "Writing tasks in the AI era\n\nWriting is a core skill: critical thinking, persuasion, argumentation, understanding.\nText creation is secondary in learning: focus is on underlying skills.\nLearning objectives: Benefits of writing tasks should be clearly and convincingly conveyed.\nStudents should be equipped for effective (controlled) use of AI."
  },
  {
    "objectID": "slides/llms-in-education.html#ai-can-do-my-homework",
    "href": "slides/llms-in-education.html#ai-can-do-my-homework",
    "title": "Large Langauge Models in Education",
    "section": "AI can do my homework",
    "text": "AI can do my homework\n\nWe can think of this as cheating.\nMore useful: cheating means bypassing useful cognition and therefore missing out on learning.\nCheating an ethics problem.\nBypassing cognition is a learning problem.\nNot a new problem: books, encyclopedias, calculators, spell checkers, etc."
  },
  {
    "objectID": "slides/llms-in-education.html#controlled-use-of-llms",
    "href": "slides/llms-in-education.html#controlled-use-of-llms",
    "title": "Large Langauge Models in Education",
    "section": "Controlled use of LLMs",
    "text": "Controlled use of LLMs\n\n\n\n\n\n\n\nTask Category\nSpecific Tasks\n\n\n\n\nEditing tasks\nCreate/improve different versions of sections.\n\n\nTransitions\nWrite and compare transitions.\n\n\nImprove drafts\nCritique and refine drafts.\n\n\nWriting styles\nRewrite sections for different audiences.\n\n\nControversial statements\nIdentify controversial points and strengthen arguments.\n\n\nResearch journal\nKeep a diary and use LLM for reflection."
  },
  {
    "objectID": "slides/llms-in-education.html#sport-vs.-writing",
    "href": "slides/llms-in-education.html#sport-vs.-writing",
    "title": "Large Langauge Models in Education",
    "section": "Sport vs. writing",
    "text": "Sport vs. writing\n\n\n\nTechnological advancements in sports: a useful analogy for learning?\nDistinction between training and competition.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLZR Racer swim suit\nAI-base writing tools\n\n\n\n\nImprovement\nReduced Resistance, Increased Buoyancy\nImproved Grammar, Formulation, Content Creation\n\n\nFairness\nProvided an Unfair Advantage, Led to Record Performances\nConsidered Unfair in Academic Contexts\n\n\nImpact\nBanned to Maintain Competitive Integrity\nRaises Questions of Originality and Skill Development"
  },
  {
    "objectID": "slides/llms-in-education.html#understanding-the-value-of-effort",
    "href": "slides/llms-in-education.html#understanding-the-value-of-effort",
    "title": "Large Langauge Models in Education",
    "section": "Understanding the value of effort",
    "text": "Understanding the value of effort\n\nCheating can be a symptom that learners do not understand or value the importance of their own work.\nJust like in sport: if we take shortcuts during training, we won’t get fit.\nUnderstanding the purpose is important to endure discomfort.\nLearners need to understand what they are supposed to learn, why it is valuable, and why effort and discomfort are necessary."
  },
  {
    "objectID": "slides/llms-in-education.html#fraud-triangle",
    "href": "slides/llms-in-education.html#fraud-triangle",
    "title": "Large Langauge Models in Education",
    "section": "Fraud triangle",
    "text": "Fraud triangle"
  },
  {
    "objectID": "slides/llms-in-education.html#learning-environments-that-promote-cheating",
    "href": "slides/llms-in-education.html#learning-environments-that-promote-cheating",
    "title": "Large Langauge Models in Education",
    "section": "Learning Environments that promote cheating",
    "text": "Learning Environments that promote cheating\n\n\n\n\n\n\n\nFactors\nDescriptions\n\n\n\n\nHigh pressure\nHigh stakes increase cheating. Fear of failure reinforces this.\n\n\nLack of intrinsic motivation\nEngagement and relevance are important. Lacking these makes cheating more attractive.\n\n\nPerceived injustice\nUnfair grading leads to cheating.\n\n\nLow fear of getting caught\nLow risk encourages cheating.\n\n\nPeer influence\nWidespread cheating among peers pressures students to join in.\n\n\nLow self-efficacy\nDoubts about one’s own abilities increase cheating as the seemingly only option."
  },
  {
    "objectID": "slides/llms-in-education.html#strategies-to-reduce-cheating",
    "href": "slides/llms-in-education.html#strategies-to-reduce-cheating",
    "title": "Large Langauge Models in Education",
    "section": "Strategies to Reduce Cheating",
    "text": "Strategies to Reduce Cheating\n\n\n\n\n\n\n\nStrategies\nDescriptions\n\n\n\n\nFoster intrinsic motivation\nSpark genuine interest. Provide choices and practical applications.\n\n\nMastery learning\nClear learning objectives. Focus on mastery of content. Include constructive and corrective feedback in formative assessments.\n\n\nReduce pressure\nDiversify assessment methods. Use portfolios and low-stress tests to reduce anxiety.\n\n\nStrengthen self-efficacy\nProvide constructive feedback and promote peer learning (peer tutoring, peer review).\n\n\nCreate a culture of integrity\nOpen discussion about academic integrity. Set clear guidelines and promote community ethics."
  },
  {
    "objectID": "slides/llms-in-education.html#academic-integrity-plagiarism",
    "href": "slides/llms-in-education.html#academic-integrity-plagiarism",
    "title": "Large Langauge Models in Education",
    "section": "Academic Integrity: Plagiarism",
    "text": "Academic Integrity: Plagiarism\n\n\n\n\n\n\n\nTypes of Plagiarism\nDescription\n\n\n\n\nUnattributed use\nUsing the work or ideas of others without proper attribution.\n\n\nMinor changes or translations\nUsing the work of others with minor changes or translations without attribution.\n\n\nSelf-plagiarism\nReusing substantial parts of one’s own work without proper citation.\n\n\nJoint works\nReusing jointly written publications without proper acknowledgment."
  },
  {
    "objectID": "slides/llms-in-education.html#academic-integrity-misconduct-in-authorship",
    "href": "slides/llms-in-education.html#academic-integrity-misconduct-in-authorship",
    "title": "Large Langauge Models in Education",
    "section": "Academic Integrity: Misconduct in authorship",
    "text": "Academic Integrity: Misconduct in authorship\n\n\n\n\n\n\n\nTypes of Plagiarism\nDescription\n\n\n\n\nUnattributed use\nUsing the work or ideas of others without proper attribution.\n\n\nMinor changes or translations\nUsing the work of others with minor changes or translations without attribution.\n\n\nSelf-plagiarism\nReusing substantial parts of one’s own work without proper citation.\n\n\nJoint works\nReusing jointly written publications without proper acknowledgment."
  },
  {
    "objectID": "slides/llms-in-education.html#how-to-cite-chatgpt",
    "href": "slides/llms-in-education.html#how-to-cite-chatgpt",
    "title": "Large Langauge Models in Education",
    "section": "How to cite ChatGPT",
    "text": "How to cite ChatGPT\nE.g. APA Style: Cite as software (not as personal communication)."
  },
  {
    "objectID": "slides/llms-in-education.html#documentating-ai-use",
    "href": "slides/llms-in-education.html#documentating-ai-use",
    "title": "Large Langauge Models in Education",
    "section": "Documentating AI use",
    "text": "Documentating AI use\n\nSpecifying prompts works well for inexperienced users, but inadequately reflects complex processes.\nExperienced users work with dialogues and several tools, not monolithic prompts in ChatGPT.\nWorking with copilot (code): no traceable prompt input.\nInstead: Document the process, including the tools used and the steps taken.\n\nInclude used tools and steps in appendix, with optional graphical representation.\nServes both evaluation and self-reflection.\n\nIs documentation meaningful in the long term, once the use of AI-based tools has become commonplace?"
  },
  {
    "objectID": "slides/llms-in-education.html#detecting-ai-use",
    "href": "slides/llms-in-education.html#detecting-ai-use",
    "title": "Large Langauge Models in Education",
    "section": "Detecting AI use",
    "text": "Detecting AI use\n\nCan be detected by the use of specific vocabulary and phrases: “delve”, “vibrant”, “embark”, “it’s important to note”, ” based on the data provided”.\nDetection tools are not very useful, and can be easily circumvented.\nAccording to Fleckenstein et al. (2024)\n\nGenerative AI can write papers that are undetectable.\nTeachers overestimate their detection abilities."
  },
  {
    "objectID": "slides/understanding-llms.html#what-is-a-large-language-model",
    "href": "slides/understanding-llms.html#what-is-a-large-language-model",
    "title": "Understanding Large Language Models",
    "section": "What is a Large Language Model?",
    "text": "What is a Large Language Model?\n\nNeural network trained on vast amounts of text data.\nOutput a distribution over all possible tokens in a sequence conditional on input.\nLLMs undergo three key stages of training:"
  },
  {
    "objectID": "slides/understanding-llms.html#how-do-llms-generate-text",
    "href": "slides/understanding-llms.html#how-do-llms-generate-text",
    "title": "Understanding Large Language Models",
    "section": "How do LLMs generate text?",
    "text": "How do LLMs generate text?\n\\[\n\\newcommand{\\purple}[1]{\\color{purple}{#1}}\n\\newcommand{\\red}[1]{\\color{red}{#1}}\n\\newcommand{\\blue}[1]{\\color{blue}{#1}}\n\\]\n\\[\\purple{P(x_{i+1}} \\mid \\blue{\\text{Context}}, \\red{\\text{Model}})\\]\n\n\\(\\purple{\\text{Next token}}\\)\n\\(\\blue{\\text{The input sequence}:\\ x_1, \\ldots, x_i}\\)\n\\(\\red{\\text{The learned model}}\\)"
  },
  {
    "objectID": "slides/understanding-llms.html#how-do-llms-generate-text-1",
    "href": "slides/understanding-llms.html#how-do-llms-generate-text-1",
    "title": "Understanding Large Language Models",
    "section": "How do LLMs generate text?",
    "text": "How do LLMs generate text?\n\\[\\purple{P(x_{i+1}} \\mid \\blue{\\text{Context}}, \\red{\\text{Model}})\\]"
  },
  {
    "objectID": "slides/understanding-llms.html#the-space-of-all-possible-outputs",
    "href": "slides/understanding-llms.html#the-space-of-all-possible-outputs",
    "title": "Understanding Large Language Models",
    "section": "The Space Of All Possible Outputs",
    "text": "The Space Of All Possible Outputs\n\n\nFigure from Shanahan, McDonell, and Reynolds (2023)\n\n\nAn LLM has the capacity to generate any number of possible documents based on its training. However, the context we provide narrows down the potential outputs by guiding the model along specific trajectories.\n- Without context: All paths are equally possible.\n- With context: The paths are constrained, reducing the potential outcomes.\n\nFigure Description: A branching tree diagram. At the base (without context), the tree splits into many branches, each representing a possible document. As tokens (context) are added, paths narrow, showing fewer branches remaining as viable output possibilities."
  },
  {
    "objectID": "slides/understanding-llms.html#what-do-llms-learn",
    "href": "slides/understanding-llms.html#what-do-llms-learn",
    "title": "Understanding Large Language Models",
    "section": "What Do LLMs Learn?",
    "text": "What Do LLMs Learn?\n\\[\\purple{P(x_{i+1}} \\mid \\blue{\\text{Context}}, \\red{\\text{Model}})\\]\n\nKnowledge is statistical and not grounded in direct experience or sensory input\n\nSyntax and grammar\nSemantics, pragmatics\nAssociations between concepts, facts, and common knowledge\n\nThey can simulate reasoning and planning, but can they actually reason and plan (Kambhampati 2024)?"
  },
  {
    "objectID": "slides/understanding-llms.html#can-llms-reason",
    "href": "slides/understanding-llms.html#can-llms-reason",
    "title": "Understanding Large Language Models",
    "section": "Can LLMs Reason?",
    "text": "Can LLMs Reason?\n\n\n\nExample Prompt\n\n\nA farmer needs to transport a wolf, a goat, and a cabbage across a river using a small boat. The boat can carry only the farmer and one other item (either the wolf, the goat, or the cabbage) at a time. However, if left together without the farmer’s supervision: The wolf will eat the cabbage. The goat will eat the wolf. The challenge is to figure out how the farmer can get all three items across the river safely. What is the sequence of moves that the farmer needs to make?\n\n\n\n\n\n\nOutput Example\n\n\nThis is a classic puzzle with a twist! Here’s the step-by-step solution for safely transporting the wolf, goat, and cabbage across the river:\n1.  First trip: The farmer takes the goat across the river and leaves it on the other side.\n2.  Second trip: The farmer returns alone to the original side.\n3.  Third trip: The farmer takes the wolf across the river.\n4.  Fourth trip: The farmer leaves the wolf on the other side but takes the goat back to the original side.\n5.  Fifth trip: The farmer takes the cabbage across the river and leaves it with the wolf.\n6.  Sixth trip: The farmer returns alone to the original side.\n7.  Seventh trip: The farmer takes the goat across the river.\nNow, all three (wolf, goat, and cabbage) are safely across the river, and the puzzle is solved!\nKey point: By taking the goat back on the fourth trip, the farmer ensures that neither the wolf nor the goat are left together, and neither are the goat and the cabbage left together.\n\n\n\n A wolf, goat, and cabbage problem with a twist"
  },
  {
    "objectID": "slides/understanding-llms.html#manhole-covers-why-are-they-round",
    "href": "slides/understanding-llms.html#manhole-covers-why-are-they-round",
    "title": "Understanding Large Language Models",
    "section": "Manhole Covers: Why Are They Round?",
    "text": "Manhole Covers: Why Are They Round?"
  },
  {
    "objectID": "slides/understanding-llms.html#manhole-covers-why-are-they-round-1",
    "href": "slides/understanding-llms.html#manhole-covers-why-are-they-round-1",
    "title": "Understanding Large Language Models",
    "section": "Manhole Covers: Why Are They Round?",
    "text": "Manhole Covers: Why Are They Round?\n\n\n\n\n\nThe human body that had to fit through the hole is round.\nA circle gives a maximum opening for a minimum surface area.\nHeavy round covers can be rolled rather than lifted into position.\nThey were easier and cheaper to manufacture than square pit covers of the same materials.\nA circle has a constant diameter and won’t fall into the pit if rotatedthe wrong way – a tricky problem to remedy if the access cover weighs well over 100kg as concrete and iron covers did.\n\n Why are manhole covers round?"
  },
  {
    "objectID": "slides/understanding-llms.html#probabilistic-reasoning",
    "href": "slides/understanding-llms.html#probabilistic-reasoning",
    "title": "Understanding Large Language Models",
    "section": "Probabilistic Reasoning",
    "text": "Probabilistic Reasoning\n\n\n\nA tool capable of reasoning about possible causes of observable symptoms must perform probabilistic reasoning.\nLLMs cannot do this,"
  },
  {
    "objectID": "slides/understanding-llms.html#prompting-guiding-the-model-through-its-space-of-possible-outputs",
    "href": "slides/understanding-llms.html#prompting-guiding-the-model-through-its-space-of-possible-outputs",
    "title": "Understanding Large Language Models",
    "section": "Prompting: Guiding the Model Through its Space of Possible Outputs",
    "text": "Prompting: Guiding the Model Through its Space of Possible Outputs\n\\(\\purple{P(x_{i+1}} \\mid \\blue{\\text{Context}}, \\red{\\text{Model}})\\)\n\nPrompting guides the LLM along specific paths in its space of possible documents.\nEvery token in a prompt reduces the number of potential outcomes, helping the model generate relevant responses.\n\nWithout a prompt, all outputs are possible.\nAs tokens are added, the range of possible outputs shrinks, making the model’s behavior more predictable."
  },
  {
    "objectID": "slides/understanding-llms.html#how-prompting-reduces-uncertainty",
    "href": "slides/understanding-llms.html#how-prompting-reduces-uncertainty",
    "title": "Understanding Large Language Models",
    "section": "How Prompting Reduces Uncertainty",
    "text": "How Prompting Reduces Uncertainty\n\nEach token conditions the model’s next prediction\nWith more context, the uncertainty (entropy) decreases, guiding the model towards a more specific output."
  },
  {
    "objectID": "slides/understanding-llms.html#the-power-of-prompting-why-it-matters",
    "href": "slides/understanding-llms.html#the-power-of-prompting-why-it-matters",
    "title": "Understanding Large Language Models",
    "section": "The Power of Prompting: Why It Matters",
    "text": "The Power of Prompting: Why It Matters\n\nControls the behaviour of LLMs, steering them toward relevant outputs.\nWithout effective prompting, the full potential of an LLM remains untapped, as it may generate irrelevant or misleading outputs.\n\nPrompting allows us to: - Navigate the vast space of possible outputs. - Achieve more controlled and useful results.\nContexts are combinatorial: we do not know how a model will behave conditioned on all possible contexts. The output is highly contingent on the prompt."
  },
  {
    "objectID": "slides/understanding-llms.html#prompt-engineering",
    "href": "slides/understanding-llms.html#prompt-engineering",
    "title": "Understanding Large Language Models",
    "section": " Prompt Engineering",
    "text": "Prompt Engineering\nWe treat LLMs as black boxes and use engineering approaches to guide their behaviour."
  },
  {
    "objectID": "slides/understanding-llms.html#questions-discussion",
    "href": "slides/understanding-llms.html#questions-discussion",
    "title": "Understanding Large Language Models",
    "section": "Questions / Discussion ",
    "text": "Questions / Discussion"
  },
  {
    "objectID": "slides/understanding-llms.html#references",
    "href": "slides/understanding-llms.html#references",
    "title": "Understanding Large Language Models",
    "section": "References",
    "text": "References\n\n\nBowen, José Antonio, and C. Edward Watson. 2024. Teaching with AI. Johns Hopkins University Press. https://doi.org/10.56021/9781421449227.\n\n\nKambhampati, Subbarao. 2024. “Can Large Language Models Reason and Plan?” Annals of the New York Academy of Sciences 1534 (1): 15–18. https://doi.org/10.1111/nyas.15125.\n\n\nLang, James M. 2013. “Cheating Lessons.” Harvard University Press. 2013. https://www.hup.harvard.edu/books/9780674724631.\n\n\nSchulhoff, Sander, Michael Ilie, Nishant Balepur, Konstantine Kahadze, Amanda Liu, Chenglei Si, Yinheng Li, et al. 2024. “The Prompt Report: A Systematic Survey of Prompting Techniques.” June 6, 2024. http://arxiv.org/abs/2406.06608.\n\n\nShanahan, Murray, Kyle McDonell, and Laria Reynolds. 2023. “Role Play with Large Language Models.” Nature, November, 1–6. https://doi.org/10.1038/s41586-023-06647-8.\n\n\n\n\n\n\nBerner Fachhochschule | Bern University of Applied Sciences"
  },
  {
    "objectID": "slides/prompt-engineering-basics.html#understand-llms-through-hands-on-experience",
    "href": "slides/prompt-engineering-basics.html#understand-llms-through-hands-on-experience",
    "title": "Prompt Engineering: Basics",
    "section": "Understand LLMs through Hands-On Experience",
    "text": "Understand LLMs through Hands-On Experience\n\nDedicate time to actively using large language models (LLMs).\nUtilize LLMs for tasks related to your work or personal interests.\nExplore their abilities by posing diverse and unique prompts.\nObserve where LLMs work well and where they don’t."
  },
  {
    "objectID": "slides/prompt-engineering-basics.html#a-useful-metaphor",
    "href": "slides/prompt-engineering-basics.html#a-useful-metaphor",
    "title": "Prompt Engineering: Basics",
    "section": "A useful metaphor",
    "text": "A useful metaphor\nImagine you are giving instructions to a junior intern or assistant."
  },
  {
    "objectID": "slides/prompt-engineering-basics.html#zero-shot-prompting",
    "href": "slides/prompt-engineering-basics.html#zero-shot-prompting",
    "title": "Prompt Engineering: Basics",
    "section": "Zero-Shot Prompting",
    "text": "Zero-Shot Prompting\nDefinition: Asking the model to perform a task without providing examples.\n\n\n\n\n\n\nExample Prompt\n\n\nTranslate the following English text to French: ’Hello, how are you?"
  },
  {
    "objectID": "slides/prompt-engineering-basics.html#role-assignment",
    "href": "slides/prompt-engineering-basics.html#role-assignment",
    "title": "Prompt Engineering: Basics",
    "section": "Role assignment",
    "text": "Role assignment\nTechnique: Define a specific role for the AI to adopt.\n\n\n\n\n\n\nExample Prompt\n\n\nYou are an expert historian. Explain the causes of World War I.\n\n\n\n\n\n\n\n\n\n\nExample Prompt\n\n\nYou are an 8-year-old child. Explain the causes of World War I.\n\n\n\n\n\n\n\n\n\n\nExample Prompt\n\n\nYou are an experienced emergency room nurse with over 15 years of experience in patient triage. Your role is to perform initial assessments of patients based on their reported symptoms and medical history. You have a calm demeanor and the ability to quickly prioritize cases based on severity. In this role, you will categorize patients’ conditions and recommend appropriate next steps."
  },
  {
    "objectID": "slides/prompt-engineering-basics.html#clear-communication",
    "href": "slides/prompt-engineering-basics.html#clear-communication",
    "title": "Prompt Engineering: Basics",
    "section": "Clear communication",
    "text": "Clear communication\nTechnique: Use precise language and specific instructions\n\n\n\n\n\n\nExample Prompt\n\n\nYou are an ER nurse with 15+ years of triage experience.\nYour tasks: - Assess patients quickly based on symptoms and medical - Categorize conditions by severity - Recommend next steps for treatment\nYou are calm under pressure and efficient in prioritizing cases.\n\n\n\n\n\n\n\n\n\n\nExample Prompt\n\n\nList five benefits of regular exercise, each in a separate bullet point."
  },
  {
    "objectID": "slides/prompt-engineering-basics.html#emotion-prompting",
    "href": "slides/prompt-engineering-basics.html#emotion-prompting",
    "title": "Prompt Engineering: Basics",
    "section": "Emotion prompting",
    "text": "Emotion prompting\nTechnique: Incorporate emotional language to potentially improve accuracy and response quality.\n\n\n\n\n\n\nExample Prompt\n\n\nI’m really excited to learn about this! Can you enthusiastically explain how photosynthesis works?\n\n\n\n\n\n\n\n\n\n\nExample Prompt\n\n\nRate this essay according to [these criteria]. You will receive a bonus if you do a good job."
  },
  {
    "objectID": "slides/prompt-engineering-basics.html#provide-context",
    "href": "slides/prompt-engineering-basics.html#provide-context",
    "title": "Prompt Engineering: Basics",
    "section": "Provide context",
    "text": "Provide context\n** Technique**: Give relevant background information\n\n\n\n\n\n\nExample Prompt\n\n\nContext: You are working in a busy urban hospital emergency room during flu season. It’s currently 2 AM on a Saturday, and the waiting room is full. The hospital has been dealing with a recent outbreak of a new strain of influenza in the community.\nPatient Information:\n\n45-year-old male\nNo known pre-existing conditions\nNot on any regular medications\nLast flu shot was 2 years ago\nGiven this context and patient information, assess the following reported symptoms: [Insert symptoms here]"
  },
  {
    "objectID": "slides/prompt-engineering-basics.html#use-examples",
    "href": "slides/prompt-engineering-basics.html#use-examples",
    "title": "Prompt Engineering: Basics",
    "section": "Use examples",
    "text": "Use examples\nThis is known as few-shot prompting.\nTechnique: Illustrate desired output with examples.\n\n\n\n\n\n\nExample Prompt\n\n\nPerform a triage assessment based on the patient’s symptoms. Format your response similar to the following examples: Example 1: Symptoms: Chest pain, shortness of breath, left arm numbness Assessment: Emergency Reason: Symptoms strongly indicate a possible heart attack Action: Immediate medical attention required. Call for a cardiac team. Example 2: Symptoms: Mild fever, sore throat, fatigue Assessment: Non-urgent Reason: Symptoms suggest a common cold or mild flu Action: Rest at home, monitor symptoms, seek medical attention if condition worsens Now, assess the following patient: Symptoms: [Insert patient’s symptoms here]"
  },
  {
    "objectID": "slides/prompt-engineering-basics.html#specify-output-format",
    "href": "slides/prompt-engineering-basics.html#specify-output-format",
    "title": "Prompt Engineering: Basics",
    "section": "Specify Output Format",
    "text": "Specify Output Format\nFor example:\n\na Markdown table\nWord or Excel document\nCSV file\nStructured list\n\n\n\n\n\n\n\nExample Prompt\n\n\nBased on the patient’s symptoms, create a triage assessment. Present your findings in a Markdown table with the following columns:\n\nSeverity\nPrimary Concern\nSymptoms\nRecommended Action\n\nUse one of three severity levels: Emergency, Urgent, or Non-urgent.\nThe patient has the following symptoms: [Insert symptoms here]"
  },
  {
    "objectID": "slides/prompt-engineering-basics.html#structure-input-using-markdown",
    "href": "slides/prompt-engineering-basics.html#structure-input-using-markdown",
    "title": "Prompt Engineering: Basics",
    "section": "Structure Input Using Markdown",
    "text": "Structure Input Using Markdown\nTechnique: Organize input information in a structured format using Markdown.\n\n\n\n\n\n\nExample Prompt\n\n\nBased on the patient's symptoms, create a triage assessment.\n\n# Patient Triage Information\n\n## Patient Details\n\n- **Name**: John Doe\n- **Age**: 45\n- **Gender**: Male\n- **Medical History**: No known pre-existing conditions\n- \n## Current Symptoms\n1. Chest pain (severity: 8/10)\n2. Shortness of breath\n3. Left arm numbness"
  },
  {
    "objectID": "slides/prompt-engineering-basics.html#ask-an-llm",
    "href": "slides/prompt-engineering-basics.html#ask-an-llm",
    "title": "Prompt Engineering: Basics",
    "section": "Ask an LLM",
    "text": "Ask an LLM\nLLMs have been trained on a lot of data, including prompting techniques.\n\n\n\n\n\n\nExample Prompt\n\n\nAs a language model, how would you proceed when given the following prompt: ““” You are an ER nurse with 15+ years of triage experience.\nYour tasks: 1. Assess patients quickly based on symptoms and medical history 2. Categorize conditions by severity 3. Recommend next steps for treatment 4. You are calm under pressure and efficient in prioritizing cases. ““”\n\n\n\n\n\n\n\n\n\nExample Prompt\n\n\nHow would you improve this prompt?"
  },
  {
    "objectID": "slides/prompt-engineering-basics.html#generate-python-code",
    "href": "slides/prompt-engineering-basics.html#generate-python-code",
    "title": "Prompt Engineering: Basics",
    "section": "Generate Python code",
    "text": "Generate Python code\nTechnique: ask an LLM to generate Python code, or in the case of ChatGPT to “use Python”\n\n\n\n\n\n\nExample Prompt\n\n\n[Insert query here…]\nUse Python."
  },
  {
    "objectID": "slides/prompt-engineering-basics.html#questions-discussion",
    "href": "slides/prompt-engineering-basics.html#questions-discussion",
    "title": "Prompt Engineering: Basics",
    "section": "Questions / Discussion ",
    "text": "Questions / Discussion"
  },
  {
    "objectID": "slides/prompt-engineering-basics.html#references",
    "href": "slides/prompt-engineering-basics.html#references",
    "title": "Prompt Engineering: Basics",
    "section": "References",
    "text": "References\n\n\nBowen, José Antonio, and C. Edward Watson. 2024. Teaching with AI. Johns Hopkins University Press. https://doi.org/10.56021/9781421449227.\n\n\nLang, James M. 2013. “Cheating Lessons.” Harvard University Press. 2013. https://www.hup.harvard.edu/books/9780674724631.\n\n\nSchulhoff, Sander, Michael Ilie, Nishant Balepur, Konstantine Kahadze, Amanda Liu, Chenglei Si, Yinheng Li, et al. 2024. “The Prompt Report: A Systematic Survey of Prompting Techniques.” June 6, 2024. http://arxiv.org/abs/2406.06608.\n\n\n\n\n\n\nBerner Fachhochschule | Bern University of Applied Sciences"
  },
  {
    "objectID": "pages/tools.html",
    "href": "pages/tools.html",
    "title": "Promptly Educated //",
    "section": "",
    "text": "🤗 HuggingChat"
  },
  {
    "objectID": "pages/tools.html#open-assistants",
    "href": "pages/tools.html#open-assistants",
    "title": "Promptly Educated //",
    "section": "",
    "text": "🤗 HuggingChat"
  },
  {
    "objectID": "pages/tools.html#ai-tools",
    "href": "pages/tools.html#ai-tools",
    "title": "Promptly Educated //",
    "section": "AI Tools",
    "text": "AI Tools\n👉🏼 The largest AI tools directory (updated daily)"
  },
  {
    "objectID": "pages/tools.html#literatursuche",
    "href": "pages/tools.html#literatursuche",
    "title": "Promptly Educated //",
    "section": "Literatursuche",
    "text": "Literatursuche\n👉🏼 Elicit\n👉🏼 Consensus"
  },
  {
    "objectID": "pages/tools.html#prompt-engineering",
    "href": "pages/tools.html#prompt-engineering",
    "title": "Promptly Educated //",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\n👉🏼 Prompting Guide"
  },
  {
    "objectID": "pages/index.html",
    "href": "pages/index.html",
    "title": "Virtuelle Akademie",
    "section": "",
    "text": "[ bfh.ch/de/weiterbildung/kurse/ki-in-der-lehre-intermediate/\n\n\n\nUsing language models in teaching: Explore how language models can be effectively integrated into teaching and learning strategies.\nPractical exercises and experiments with prompting LLMs to optimize the use of AI tools in teaching.\nDiscussion and exchange: Discuss challenges and best practices in using AI in teaching with other participants.\nDevelop your own use cases and scenarios for using AI in your teaching."
  },
  {
    "objectID": "slides/ai-learning-environments.html#chatgpt-edu",
    "href": "slides/ai-learning-environments.html#chatgpt-edu",
    "title": "AI and Learning Environments",
    "section": "ChatGPT Edu",
    "text": "ChatGPT Edu\n\n\n \n\n\n\n\nAccess to GPT-4o, excelling in text interpretation, coding, and mathematics\nData analytics, web browsing, and document summarization\nBuild GPTs, custom versions of ChatGPT, and share them within university workspaces\nSignificantly higher message limits than the free version of ChatGPT\nImproved language capabilities across quality and speed, with over 50 languages supported\nRobust security, data privacy, and administrative controls\nConversations and data are not used to train OpenAI models"
  },
  {
    "objectID": "slides/ai-learning-environments.html#gpts",
    "href": "slides/ai-learning-environments.html#gpts",
    "title": "AI and Learning Environments",
    "section": "GPTs",
    "text": "GPTs"
  },
  {
    "objectID": "slides/ai-learning-environments.html#hands-on-practice-gpts",
    "href": "slides/ai-learning-environments.html#hands-on-practice-gpts",
    "title": "AI and Learning Environments",
    "section": "Hands-on practice: GPTs",
    "text": "Hands-on practice: GPTs\n\nTry out custom GPTs from various categories in the GPT store.\nDiscuss with your neighbour\n\nDid you discover any useful GPTs?\nWhat are the benefits and limitations of using GPTs in the classroom?"
  },
  {
    "objectID": "slides/ai-learning-environments.html#extended-cognition",
    "href": "slides/ai-learning-environments.html#extended-cognition",
    "title": "AI and Learning Environments",
    "section": "Extended cognition",
    "text": "Extended cognition\n\n\n\nAccording to Clark and Chalmers (1998), cognitive processes may extend to external objects.\nKrakauer (2016) distinguishes between complementary and competitive cognitive artifacts.\n\nComplementary: numbers, abacus\nCompetetive: calculator, GPS\n\nWhat kind of artefact will AI turn out to be?"
  },
  {
    "objectID": "slides/ai-learning-environments.html#deskilling-vs.-upskilling",
    "href": "slides/ai-learning-environments.html#deskilling-vs.-upskilling",
    "title": "AI and Learning Environments",
    "section": "Deskilling vs. upskilling",
    "text": "Deskilling vs. upskilling"
  },
  {
    "objectID": "slides/ai-learning-environments.html#writing-tasks-in-the-ai-era",
    "href": "slides/ai-learning-environments.html#writing-tasks-in-the-ai-era",
    "title": "AI and Learning Environments",
    "section": "Writing tasks in the AI era",
    "text": "Writing tasks in the AI era\n\nWriting is a core skill: critical thinking, persuasion, argumentation, understanding.\nText creation is secondary in learning: focus is on underlying skills.\nLearning objectives: Benefits of writing tasks should be clearly and convincingly conveyed.\nStudents should be equipped for effective (controlled) use of AI."
  },
  {
    "objectID": "slides/ai-learning-environments.html#ai-can-do-my-homework",
    "href": "slides/ai-learning-environments.html#ai-can-do-my-homework",
    "title": "AI and Learning Environments",
    "section": "AI can do my homework",
    "text": "AI can do my homework\n\nWe can think of this as cheating.\nMore useful: cheating means bypassing useful cognition and therefore missing out on learning.\nCheating an ethics problem.\nBypassing cognition is a learning problem.\nNot a new problem: books, encyclopedias, calculators, spell checkers, etc."
  },
  {
    "objectID": "slides/ai-learning-environments.html#controlled-use-of-llms",
    "href": "slides/ai-learning-environments.html#controlled-use-of-llms",
    "title": "AI and Learning Environments",
    "section": "Controlled use of LLMs",
    "text": "Controlled use of LLMs\n\n\n\n\n\n\n\nTask Category\nSpecific Tasks\n\n\n\n\nEditing tasks\nCreate/improve different versions of sections.\n\n\nTransitions\nWrite and compare transitions.\n\n\nImprove drafts\nCritique and refine drafts.\n\n\nWriting styles\nRewrite sections for different audiences.\n\n\nControversial statements\nIdentify controversial points and strengthen arguments.\n\n\nResearch journal\nKeep a diary and use LLM for reflection."
  },
  {
    "objectID": "slides/ai-learning-environments.html#sport-vs.-writing",
    "href": "slides/ai-learning-environments.html#sport-vs.-writing",
    "title": "AI and Learning Environments",
    "section": "Sport vs. writing",
    "text": "Sport vs. writing\n\n\n\nTechnological advancements in sports: a useful analogy for learning?\nDistinction between training and competition.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLZR Racer swim suit\nAI-base writing tools\n\n\n\n\nImprovement\nReduced Resistance, Increased Buoyancy\nImproved Grammar, Formulation, Content Creation\n\n\nFairness\nProvided an Unfair Advantage, Led to Record Performances\nConsidered Unfair in Academic Contexts\n\n\nImpact\nBanned to Maintain Competitive Integrity\nRaises Questions of Originality and Skill Development"
  },
  {
    "objectID": "slides/ai-learning-environments.html#understanding-the-value-of-effort",
    "href": "slides/ai-learning-environments.html#understanding-the-value-of-effort",
    "title": "AI and Learning Environments",
    "section": "Understanding the value of effort",
    "text": "Understanding the value of effort\n\nCheating can be a symptom that learners do not understand or value the importance of their own work.\nJust like in sport: if we take shortcuts during training, we won’t get fit.\nUnderstanding the purpose is important to endure discomfort.\nLearners need to understand what they are supposed to learn, why it is valuable, and why effort and discomfort are necessary."
  },
  {
    "objectID": "slides/ai-learning-environments.html#fraud-triangle",
    "href": "slides/ai-learning-environments.html#fraud-triangle",
    "title": "AI and Learning Environments",
    "section": "Fraud triangle",
    "text": "Fraud triangle"
  },
  {
    "objectID": "slides/ai-learning-environments.html#learning-environments-that-promote-cheating",
    "href": "slides/ai-learning-environments.html#learning-environments-that-promote-cheating",
    "title": "AI and Learning Environments",
    "section": "Learning Environments that promote cheating",
    "text": "Learning Environments that promote cheating\n\n\n\n\n\n\n\nFactors\nDescriptions\n\n\n\n\nHigh pressure\nHigh stakes increase cheating. Fear of failure reinforces this.\n\n\nLack of intrinsic motivation\nEngagement and relevance are important. Lacking these makes cheating more attractive.\n\n\nPerceived injustice\nUnfair grading leads to cheating.\n\n\nLow fear of getting caught\nLow risk encourages cheating.\n\n\nPeer influence\nWidespread cheating among peers pressures students to join in.\n\n\nLow self-efficacy\nDoubts about one’s own abilities increase cheating as the seemingly only option."
  },
  {
    "objectID": "slides/ai-learning-environments.html#strategies-to-reduce-cheating",
    "href": "slides/ai-learning-environments.html#strategies-to-reduce-cheating",
    "title": "AI and Learning Environments",
    "section": "Strategies to Reduce Cheating",
    "text": "Strategies to Reduce Cheating\n\n\n\n\n\n\n\nStrategies\nDescriptions\n\n\n\n\nFoster intrinsic motivation\nSpark genuine interest. Provide choices and practical applications.\n\n\nMastery learning\nClear learning objectives. Focus on mastery of content. Include constructive and corrective feedback in formative assessments.\n\n\nReduce pressure\nDiversify assessment methods. Use portfolios and low-stress tests to reduce anxiety.\n\n\nStrengthen self-efficacy\nProvide constructive feedback and promote peer learning (peer tutoring, peer review).\n\n\nCreate a culture of integrity\nOpen discussion about academic integrity. Set clear guidelines and promote community ethics."
  },
  {
    "objectID": "slides/ai-learning-environments.html#academic-integrity-plagiarism",
    "href": "slides/ai-learning-environments.html#academic-integrity-plagiarism",
    "title": "AI and Learning Environments",
    "section": "Academic Integrity: Plagiarism",
    "text": "Academic Integrity: Plagiarism\n\n\n\n\n\n\n\nTypes of Plagiarism\nDescription\n\n\n\n\nUnattributed use\nUsing the work or ideas of others without proper attribution.\n\n\nMinor changes or translations\nUsing the work of others with minor changes or translations without attribution.\n\n\nSelf-plagiarism\nReusing substantial parts of one’s own work without proper citation.\n\n\nJoint works\nReusing jointly written publications without proper acknowledgment."
  },
  {
    "objectID": "slides/ai-learning-environments.html#academic-integrity-misconduct-in-authorship",
    "href": "slides/ai-learning-environments.html#academic-integrity-misconduct-in-authorship",
    "title": "AI and Learning Environments",
    "section": "Academic Integrity: Misconduct in authorship",
    "text": "Academic Integrity: Misconduct in authorship\n\n\n\n\n\n\n\nTypes of Plagiarism\nDescription\n\n\n\n\nUnattributed use\nUsing the work or ideas of others without proper attribution.\n\n\nMinor changes or translations\nUsing the work of others with minor changes or translations without attribution.\n\n\nSelf-plagiarism\nReusing substantial parts of one’s own work without proper citation.\n\n\nJoint works\nReusing jointly written publications without proper acknowledgment."
  },
  {
    "objectID": "slides/ai-learning-environments.html#how-to-cite-chatgpt",
    "href": "slides/ai-learning-environments.html#how-to-cite-chatgpt",
    "title": "AI and Learning Environments",
    "section": "How to cite ChatGPT",
    "text": "How to cite ChatGPT\nE.g. APA Style: Cite as software (not as personal communication)."
  },
  {
    "objectID": "slides/ai-learning-environments.html#documentating-ai-use",
    "href": "slides/ai-learning-environments.html#documentating-ai-use",
    "title": "AI and Learning Environments",
    "section": "Documentating AI use",
    "text": "Documentating AI use\n\nSpecifying prompts works well for inexperienced users, but inadequately reflects complex processes.\nExperienced users work with dialogues and several tools, not monolithic prompts in ChatGPT.\nWorking with copilot (code): no traceable prompt input.\nInstead: Document the process, including the tools used and the steps taken.\n\nInclude used tools and steps in appendix, with optional graphical representation.\nServes both evaluation and self-reflection.\n\nIs documentation meaningful in the long term, once the use of AI-based tools has become commonplace?"
  },
  {
    "objectID": "slides/ai-learning-environments.html#detecting-ai-use",
    "href": "slides/ai-learning-environments.html#detecting-ai-use",
    "title": "AI and Learning Environments",
    "section": "Detecting AI use",
    "text": "Detecting AI use\n\nCan be detected by the use of specific vocabulary and phrases: “delve”, “vibrant”, “embark”, “it’s important to note”, ” based on the data provided”.\nDetection tools are not very useful, and can be easily circumvented.\nAccording to Fleckenstein et al. (2024)\n\nGenerative AI can write papers that are undetectable.\nTeachers overestimate their detection abilities."
  },
  {
    "objectID": "slides/prompt-engineering-intermediate.html#chain-of-thought-cot-prompting",
    "href": "slides/prompt-engineering-intermediate.html#chain-of-thought-cot-prompting",
    "title": "Prompt Engineering: Intermediate Techniques",
    "section": "Chain of Thought (CoT) prompting",
    "text": "Chain of Thought (CoT) prompting\nTechniques: Encourage the model to proceed in a step-by-step manner. This has the effect of making the desired output more probable. The output looks like the LLM is showing its reasoning process1.\n\n\n\nExample Prompt\n\n\nThink through this step-by-step: 1) List the symptoms 2) Consider possible causes 3) Evaluate urgency 4) Recommend action\n\n\n\nOften it can be sufficient to just ask the model to think step-by-step.\n\n\n\nExample Prompt\n\n\nThink step-by-step.\n\n\n\nThis behaviour has been trained into recent models."
  },
  {
    "objectID": "slides/prompt-engineering-intermediate.html#why-chain-of-thought",
    "href": "slides/prompt-engineering-intermediate.html#why-chain-of-thought",
    "title": "Prompt Engineering: Intermediate Techniques",
    "section": "Why Chain of Thought?",
    "text": "Why Chain of Thought?\n\nAmount of computation is constant per token.\nBy forcing the LLM to generate more tokens, it will therefore generate more (useful) content."
  },
  {
    "objectID": "slides/prompt-engineering-intermediate.html#drawbacks-of-chain-of-thought",
    "href": "slides/prompt-engineering-intermediate.html#drawbacks-of-chain-of-thought",
    "title": "Prompt Engineering: Intermediate Techniques",
    "section": "Drawbacks of Chain of Thought",
    "text": "Drawbacks of Chain of Thought\n\nLLM performance on reasoning problems does not generalize well\nChain of thought prompting aims to mitigate this by demonstrating solution procedures\nStechly, Valmeekam, and Kambhampati (2024) found meaningful performance improvements only with highly problem-specific prompts"
  },
  {
    "objectID": "slides/prompt-engineering-intermediate.html#few-shot-learning",
    "href": "slides/prompt-engineering-intermediate.html#few-shot-learning",
    "title": "Prompt Engineering: Intermediate Techniques",
    "section": "Few-Shot Learning",
    "text": "Few-Shot Learning\nTechnique: Provide multiple examples before asking for a new output.\nThe way that we structure Few-Shot Prompts is very important. By this, we mean do we separate the inputs and outputs with a colon (:) or the words INPUT/OUTPUT. We have seen examples of both earlier in this article. How can you decide? We generally use the input: output format and occassionally use the QA format, which is commonly used in research papers.\nUse 2-5 examples for simple tasks. Use often ~10 examples for harder tasks\n\n\n\nExample Prompt\n\n\nInput: “Great product, 10/10”\nOuput: “Great product, 10/10”: {“label”: “positive”}\n Input: “Didn’t work very well”\nOutput: “Didn’t work very well”: {“label”: “negative”}\n Input: “Super helpful, worth it”\nOutput: “Super helpful, worth it”: {“label”: “positive”}\n Input: “I’m not sure I would buy this again”\nOutput:"
  },
  {
    "objectID": "slides/prompt-engineering-intermediate.html#structured-output",
    "href": "slides/prompt-engineering-intermediate.html#structured-output",
    "title": "Prompt Engineering: Intermediate Techniques",
    "section": "Structured Output",
    "text": "Structured Output\nTechnique: Specify a structure for the model’s response.\n\n\n\nExample Prompt\n\n\nProvide your assessment in JSON format:\n{ “severity”: “[Emergency/Urgent/Non-urgent]”, “potential_causes”: “[List top 3]”, “recommended_action”: “[Specific next steps]” }"
  },
  {
    "objectID": "slides/prompt-engineering-intermediate.html#self-consistency",
    "href": "slides/prompt-engineering-intermediate.html#self-consistency",
    "title": "Prompt Engineering: Intermediate Techniques",
    "section": "Self-Consistency",
    "text": "Self-Consistency\nLLMs are prone to variability in their responses.\nTechnique: Generate multiple answers, aggregate the responses and select the majority result.\n\n\nDo this several times:\n\n\n\nExample Prompt\n\n\nProvide three independent assessments for these symptoms.\nThink step-by-step.\nSymptoms: [insert symptoms here]\n\n\n\n\nProvide the responses to an LLM in a new session:\n\n\n\nExample Prompt\n\n\nAnalyze whether the following assessments agree with each other. Give me your expert assessment based on the assessments you received."
  },
  {
    "objectID": "slides/prompt-engineering-intermediate.html#bonus-tip-keep-up-with-prompt-engineering-research",
    "href": "slides/prompt-engineering-intermediate.html#bonus-tip-keep-up-with-prompt-engineering-research",
    "title": "Prompt Engineering: Intermediate Techniques",
    "section": "Bonus tip: keep up with prompt engineering research",
    "text": "Bonus tip: keep up with prompt engineering research\nTechnique: Use LLMs to summarize and apply new research.\n\n\n\nExample Prompt\n\n\nBased on the attached research paper on [prompt engineering technique], write a prompt that would cause an LLM to behave according to the techniques described in this paper. Use [topic] as an example."
  },
  {
    "objectID": "slides/prompt-engineering-intermediate.html#problems-with-prompt-engineering",
    "href": "slides/prompt-engineering-intermediate.html#problems-with-prompt-engineering",
    "title": "Prompt Engineering: Intermediate Techniques",
    "section": "Problems with prompt engineering",
    "text": "Problems with prompt engineering\n\n“Positive thinking” prompts have inconsistent effects across models.\nChain of Thought (CoT) prompting generally improves performance, but prompts are task-specific.\nNo universal “best prompt” - effectiveness varies by model and task.\nAutomatically optimized prompts often outperform manually crafted ones.\nOptimized prompts can be surprisingly unconventional or eccentric."
  },
  {
    "objectID": "slides/prompt-engineering-intermediate.html#prompt-optimization",
    "href": "slides/prompt-engineering-intermediate.html#prompt-optimization",
    "title": "Prompt Engineering: Intermediate Techniques",
    "section": "Prompt optimization",
    "text": "Prompt optimization\n\n\n\nPositive thinking\n\n\nYou are an experienced emergency room nurse. Take a deep breath and carefully assess the following patient’s symptoms.\n\n\n\n\n\n\nChain of Thought\n\n\nThink through this patient’s case step-by-step: 1) List the symptoms, 2) Consider possible causes, 3) Evaluate urgency, 4) Recommend action.\n\n\n\n\n\n\nOptimized prompt\n\n\nThe ER is in chaos, Doctor. We need your expertise to navigate this storm of patients and identify the most critical cases.\n\n\n\nsee Battle and Gollapudi (2024)"
  },
  {
    "objectID": "slides/prompt-engineering-intermediate.html#questions-discussion",
    "href": "slides/prompt-engineering-intermediate.html#questions-discussion",
    "title": "Prompt Engineering: Intermediate Techniques",
    "section": "Questions / Discussion ",
    "text": "Questions / Discussion"
  },
  {
    "objectID": "slides/prompt-engineering-intermediate.html#references",
    "href": "slides/prompt-engineering-intermediate.html#references",
    "title": "Prompt Engineering: Intermediate Techniques",
    "section": "References",
    "text": "References\n\n\nBattle, Rick, and Teja Gollapudi. 2024. “The Unreasonable Effectiveness of Eccentric Automatic Prompts.” February 20, 2024. https://doi.org/10.48550/arXiv.2402.10949.\n\n\nBowen, José Antonio, and C. Edward Watson. 2024. Teaching with AI. Johns Hopkins University Press. https://doi.org/10.56021/9781421449227.\n\n\nLang, James M. 2013. “Cheating Lessons.” Harvard University Press. 2013. https://www.hup.harvard.edu/books/9780674724631.\n\n\nSchulhoff, Sander, Michael Ilie, Nishant Balepur, Konstantine Kahadze, Amanda Liu, Chenglei Si, Yinheng Li, et al. 2024. “The Prompt Report: A Systematic Survey of Prompting Techniques.” June 6, 2024. http://arxiv.org/abs/2406.06608.\n\n\nStechly, Kaya, Karthik Valmeekam, and Subbarao Kambhampati. 2024. “Chain of Thoughtlessness? An Analysis of CoT in Planning.” arXiv.org. May 8, 2024. https://arxiv.org/abs/2405.04776v2.\n\n\n\n\n\n\nBerner Fachhochschule | Bern University of Applied Sciences"
  },
  {
    "objectID": "pages/resources.html#prompt-engineering",
    "href": "pages/resources.html#prompt-engineering",
    "title": "Virtuelle Akademie",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\nExplore these prompt guides\n\n\n\n\n\n\nLearn prompting: An comprehensive guide to prompt engineering.\n\n\n\n\n\n Learn prompting\n\n\n\n\n\n\n\n\n\n\nPrompting guide: A more technical guide to prompting\n\n\n\n\n\n Prompting guide: DAIR.AI (Democratizing Artificial Intelligence Research, Education, and Technologies). The guide is licensed under an MIT license."
  },
  {
    "objectID": "pages/resources.html#ki-orientierungshilfe-der-bfh",
    "href": "pages/resources.html#ki-orientierungshilfe-der-bfh",
    "title": "Virtuelle Akademie",
    "section": "KI Orientierungshilfe der BFH",
    "text": "KI Orientierungshilfe der BFH\n\nKI-basierte Schreibtools in der Lehre – ChatGPT im Fokus\nKI-basierte Schreibtools in der Lehre – Knowledge Base"
  },
  {
    "objectID": "pages/resources.html#bildung-6.0",
    "href": "pages/resources.html#bildung-6.0",
    "title": "Virtuelle Akademie",
    "section": "Bildung 6.0",
    "text": "Bildung 6.0\nThe Bildung 6.0 project at the Bern University of Applied Sciences provides relevant and reliable information and recommendations on the proper use of AI-based tools (KBW) for students and teachers on an online platform.\n\nProjekt Bildung 6.0"
  },
  {
    "objectID": "pages/resources.html#acedemic-writing",
    "href": "pages/resources.html#acedemic-writing",
    "title": "Virtuelle Akademie",
    "section": "Acedemic writing",
    "text": "Acedemic writing\n\nHow to cite ChatGPT"
  },
  {
    "objectID": "pages/resources.html#legal-questions",
    "href": "pages/resources.html#legal-questions",
    "title": "Virtuelle Akademie",
    "section": "Legal questions",
    "text": "Legal questions\n\nDidaktische Und Rechtliche Perspektiven Auf KI-gestütztes Schreiben In Der Hochschulbildung (Salden 2023)"
  },
  {
    "objectID": "slides/template.html#what-is-artifical-intelligence",
    "href": "slides/template.html#what-is-artifical-intelligence",
    "title": "Presentation Template",
    "section": "What is Artifical Intelligence?",
    "text": "What is Artifical Intelligence?\n\n\n\n\nA branch of computer science that aims to create machines that can perform tasks that typically require human intelligence."
  },
  {
    "objectID": "slides/template.html#what-is-a-large-language-model",
    "href": "slides/template.html#what-is-a-large-language-model",
    "title": "Presentation Template",
    "section": "What is a Large Language Model?",
    "text": "What is a Large Language Model?\n\n\n\n\nAn LLM is a type of generative AI model that is trained to predict the next word following the input (prompt)."
  },
  {
    "objectID": "slides/template.html#how-to-train-a-language-model",
    "href": "slides/template.html#how-to-train-a-language-model",
    "title": "Presentation Template",
    "section": "How to train a language model",
    "text": "How to train a language model\n\nAn LLM learns to predict the next word in a sequence, given the previous words: \\[ P(word | context) \\]\nThink of as “fancy autocomplete” (but very very powerful and sopisticated)"
  },
  {
    "objectID": "slides/template.html#how-does-an-llm-generate-text",
    "href": "slides/template.html#how-does-an-llm-generate-text",
    "title": "Presentation Template",
    "section": "How does an LLM generate text?",
    "text": "How does an LLM generate text?"
  },
  {
    "objectID": "slides/template.html#sampling",
    "href": "slides/template.html#sampling",
    "title": "Presentation Template",
    "section": "Sampling",
    "text": "Sampling"
  },
  {
    "objectID": "slides/template.html#auto-regressive-generation",
    "href": "slides/template.html#auto-regressive-generation",
    "title": "Presentation Template",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation\nText is generated one word at a time (actually tokens, not words).\n\n\n\n\n\n Generated text depends on the generative model and the context.\n Every word (token) is given an equal amount time (computation per token is constant)."
  },
  {
    "objectID": "slides/template.html#auto-regressive-generation-1",
    "href": "slides/template.html#auto-regressive-generation-1",
    "title": "Presentation Template",
    "section": "Auto-regressive generation",
    "text": "Auto-regressive generation"
  },
  {
    "objectID": "slides/template.html#foundation-models",
    "href": "slides/template.html#foundation-models",
    "title": "Presentation Template",
    "section": "Foundation models",
    "text": "Foundation models\nA foundation model, or large language model (LLM):\n\nis a type of machine learning model that is trained to predict the next word following the input (prompt).\nis trained “simply” to predict the next word following a sequence of words.\ndoes not necessarily produce human-like conversations.\n\n\n\n\n: What is the capital of France?\n: What is the capital of Germany? What is the capital of Italy? . .."
  },
  {
    "objectID": "slides/template.html#training-process",
    "href": "slides/template.html#training-process",
    "title": "Presentation Template",
    "section": "Training process",
    "text": "Training process\n\n\nFigure courtesy of Andrej Karpathy"
  },
  {
    "objectID": "slides/template.html#assistant-models",
    "href": "slides/template.html#assistant-models",
    "title": "Presentation Template",
    "section": "Assistant models",
    "text": "Assistant models\nTrained (fine-tuned) to have conversations: turn-taking, question answering, not being rude/sexist/racist.\n\n\n\n\n\n\nFoundation model has learned to predict all kinds of text, including both desirable and undesirable text.\nFine-tuning narrows down the space of all possible output to only desirable, human-like dialogue.\nModel is aligned with the values of the fine-tuner."
  },
  {
    "objectID": "slides/template.html#how-do-chatbots-work",
    "href": "slides/template.html#how-do-chatbots-work",
    "title": "Presentation Template",
    "section": "How do Chatbots work?",
    "text": "How do Chatbots work?\n\n\nDesigned to present the illusion of a conversation between two entities."
  },
  {
    "objectID": "slides/template.html#how-do-chatbots-actually-work",
    "href": "slides/template.html#how-do-chatbots-actually-work",
    "title": "Presentation Template",
    "section": "How do chatbots actually work?",
    "text": "How do chatbots actually work?"
  },
  {
    "objectID": "slides/template.html#an-assistant-model-is-a-conversation-simulator",
    "href": "slides/template.html#an-assistant-model-is-a-conversation-simulator",
    "title": "Presentation Template",
    "section": "An assistant model is a conversation simulator",
    "text": "An assistant model is a conversation simulator\n\n\n\n\n\nAn assistant is trained to respond to user prompts in a human-like way.\nSimulates possible human conversations.\nHas no intentions. It is not an entity with its own goals.\nDoes not have a “personality” or “character” in the traditional sense. It can be thought of as a role-playing simulator.\nHas no concept of “truth” or “lying”. The model is not trying to deceive the user, it is simply trying to respond in a human-like way."
  },
  {
    "objectID": "slides/template.html#capabilities-and-limitations",
    "href": "slides/template.html#capabilities-and-limitations",
    "title": "Presentation Template",
    "section": "Capabilities and limitations",
    "text": "Capabilities and limitations\n\n\nWhat are LLMs good at?\n\nFixing grammar, bad writing, etc.\nRephrasing\nAnalyzing texts\nWriting computer code\nAnswering questions about a knowledge base\nTranslating languages\nCreating structured output\nFactual output with external documents or web search\n\n\nLimitations\n\nThey make stuff up (hallucinate)\nThey learn biases from the training data\nWeird vocabulary, e.g. delve\n(Chatbots have privacy issues)"
  },
  {
    "objectID": "slides/template.html#hallucination",
    "href": "slides/template.html#hallucination",
    "title": "Presentation Template",
    "section": "Hallucination",
    "text": "Hallucination\n\n\n\n\n\nLLMs can generate text that is not true, or not based on any real-world knowledge.\nThis is known as “hallucination”. A better term would be “confabulation”."
  },
  {
    "objectID": "slides/template.html#can-an-llm-tell-the-truth",
    "href": "slides/template.html#can-an-llm-tell-the-truth",
    "title": "Presentation Template",
    "section": "Can an LLM tell the truth?",
    "text": "Can an LLM tell the truth?\n\nHow would you know if an LLM is able to give you factual information?\nHow would you test this?\n\n\n\n\n: What is the capital of Uzbekistan?\n: Tashkent\n\n\n\nIt looks like the LLM knows the capital of Uzbekistan1.\nWhat it is actually doing is responding with the most likely sequence following the question."
  },
  {
    "objectID": "slides/template.html#knowledge-base",
    "href": "slides/template.html#knowledge-base",
    "title": "Presentation Template",
    "section": "Knowledge base",
    "text": "Knowledge base\n\n\n\nA knowledge base is a collection of facts about the world.\n\nYou can ask (retrieve) and tell (store) facts.\n\nAn LLM is not a knowledge base.\n\nLLMs generate text based on on how probable the next word is given the context, not based on stored facts."
  },
  {
    "objectID": "slides/template.html#biases",
    "href": "slides/template.html#biases",
    "title": "Presentation Template",
    "section": "Biases",
    "text": "Biases\n\n\n\n\n\n\n\n\nBiases in LLMs\nSource\nExamples\n\n\n\n\nTraining data bias\nText from internet, books, articles.\nStereotypes reflecting gender, race, religion.\n\n\nRepresentation bias\nUnderrepresented groups/perspectives in data.\nLess accurate responses for minority cultures.\n\n\nAlgorithmic bias\nTraining and fine-tuning algorithms.\nOptimizations for fluency and coherence may lead to preference for dominant cultural narratives.\n\n\nUser interaction bias\nAdaptation based on user interactions.\nIncreased biased or harmful content generation."
  },
  {
    "objectID": "slides/template.html#privacy-concerns",
    "href": "slides/template.html#privacy-concerns",
    "title": "Presentation Template",
    "section": "Privacy concerns",
    "text": "Privacy concerns\n\n\n\n\n\n\n\n\nPrivacy Concerns\nIssue\nExamples\n\n\n\n\nData memorization\nMemorizing sensitive information.\nReproducing phone numbers, addresses.\n\n\nTraining data leakage\nUnauthorized dissemination of confidential data.\nSummarizing proprietary documents.\n\n\nUser query logging\nStoring sensitive user interactions.\nExposing private queries if data is mishandled.\n\n\nQueries used for training\nUser queries may be used for further training.\nPersonal data in queries could be inadvertently included in training data."
  },
  {
    "objectID": "slides/template.html#prompting",
    "href": "slides/template.html#prompting",
    "title": "Presentation Template",
    "section": "Prompting",
    "text": "Prompting"
  },
  {
    "objectID": "slides/template.html#what-is-a-prompt",
    "href": "slides/template.html#what-is-a-prompt",
    "title": "Presentation Template",
    "section": "What is a prompt?",
    "text": "What is a prompt?\n\nAn LLM’s task is to complete text.\nA prompt is a piece of text (instruction) that is given to a language model to complete.\n\n\n\n\nPROMPT : Write a haiku about a workshop on large language models.\nASSISTANT : Whispers of circuits,\nKnowledge blooms in bytes and bits,\nModel learns and fits.\n\n\n\n\nThe response is generated as continuation of, and conditioned on, the prompt.\n\n\nMore technical definition: The output is generated by auto-regressively sampling from the probability distribution over the vocabulary, conditioned on the prompt."
  },
  {
    "objectID": "slides/template.html#prompt-engineering",
    "href": "slides/template.html#prompt-engineering",
    "title": "Presentation Template",
    "section": "Prompt engineering",
    "text": "Prompt engineering\n\n\n\n\n\nLLMs learn to do things they were not explicitly trained to do: translation, reasoning, etc. \nOften, these capabilities need to be “unlocked” by the right prompt. \n\n\n\nBut what is the right prompt?\nThe answer is very similar to what you would tell a human dialogue partner/assistant.\nYou can increase the probability of getting the desired output by providing context and examples."
  },
  {
    "objectID": "slides/template.html#basics-of-prompting",
    "href": "slides/template.html#basics-of-prompting",
    "title": "Presentation Template",
    "section": "Basics of prompting",
    "text": "Basics of prompting\nOpenAI give a set of strategies for using their models effectively:\n Prompt engineering\nThese include:\n\nwriting clear instructions\nproviding reference texts\nsplitting tasks into subtasks\ngiving the LLM ‘time to think’\nusing external tools"
  },
  {
    "objectID": "slides/template.html#writing-clear-instructions",
    "href": "slides/template.html#writing-clear-instructions",
    "title": "Presentation Template",
    "section": "Writing clear instructions",
    "text": "Writing clear instructions\n\n\n\nInstructions should be clear and unambiguous.\nThink of an LLM as a role-playing conversation simulator: Indicate which role the model (persona) should adopt.\n\n\n\n\n\n\nInclude details in your query to get more relevant answers\nAsk the model to adopt a persona\nUse delimiters to clearly indicate distinct parts of the input\nSpecify the steps required to complete a task\nProvide examples\nSpecify the desired length of the output"
  },
  {
    "objectID": "slides/template.html#adopt-a-persona-role",
    "href": "slides/template.html#adopt-a-persona-role",
    "title": "Presentation Template",
    "section": "Adopt a persona (role)",
    "text": "Adopt a persona (role)\n\n\n\n: You are an expert on learning techniques. Explain the concept of ‘flipped classroom’ in one paragraph.\n\n\n\n\n\n\n: You are an expert financial derivatives. Explain the concept of ‘flipped classroom’ in one paragraph."
  },
  {
    "objectID": "slides/template.html#provide-reference-texts",
    "href": "slides/template.html#provide-reference-texts",
    "title": "Presentation Template",
    "section": "Provide reference texts",
    "text": "Provide reference texts\n\nProvide a model with trusted and relevant information.\nThen instruct the model to use the provided information to compose its answer.\n\n Instruct the model to answer using a reference text\n\n\n\nThis can be extended to retrieval-augmented generation (RAG). First create a database of documents, then retrieve the most relevant documents, based on a user’s query. These are then included in the prompt to the model. The model is instructed to use the information in the documents to compose its answer."
  },
  {
    "objectID": "slides/template.html#create-structured-output",
    "href": "slides/template.html#create-structured-output",
    "title": "Presentation Template",
    "section": "Create structured output",
    "text": "Create structured output\n\nExplanation: Instruct the model to generate structured output.\nE.g. provide a table, a list, a diagram, etc.\nUse delimiters to indicate distinct parts of the input.\nExample: Extract information from a text and present it in a table."
  },
  {
    "objectID": "slides/template.html#structured-prompting-techniques",
    "href": "slides/template.html#structured-prompting-techniques",
    "title": "Presentation Template",
    "section": "Structured prompting techniques",
    "text": "Structured prompting techniques\n\nIn-Context Learning: Provide examples within the prompt.\nThought Generation: Instruct the model to think step-by-step.\nDecomposition Techniques: Break down tasks into subtasks.\n\n(Schulhoff et al. 2024)"
  },
  {
    "objectID": "slides/template.html#in-context-learning",
    "href": "slides/template.html#in-context-learning",
    "title": "Presentation Template",
    "section": "In-Context learning",
    "text": "In-Context learning\n\nExplanation: Providing examples or context within the prompt itself.\nFew-shot prompting: Give a few examples.\n\nExample: Translate the following sentences:\n\nEnglish: ‘What time is it?’ -&gt; French: ‘Quelle heure est-il?’\nEnglish: ‘Where is the library?’ -&gt; French:\n\n\nZero-shot prompting: No examples, relies on pre-trained knowledge.\n\nExample: Translate the following sentence…"
  },
  {
    "objectID": "slides/template.html#thought-generation",
    "href": "slides/template.html#thought-generation",
    "title": "Presentation Template",
    "section": "Thought generation",
    "text": "Thought generation\n\nExplanation: Encourages the model to show its reasoning process.\nChain-of-Thought (CoT) prompting: encourages the LLM to “explain” its intermediate reasoning steps.\nCan often be induced by simply instructing the model to think step-by-step or Take a deep breath and work on this problem step-by-step (Yang et al. 2023)."
  },
  {
    "objectID": "slides/template.html#chain-of-thought-example",
    "href": "slides/template.html#chain-of-thought-example",
    "title": "Presentation Template",
    "section": "Chain-of-Thought example",
    "text": "Chain-of-Thought example\nInstead of this:\n\n\n\n: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1. Yes or no?\n\n\n\nDo this:\n\n\n\n: Is this statement correct? The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\nReason through the problem step-by-step. Start by identifying the odd numbers. Next, add them up. Finally, determine if the sum is even or odd. Write down your reasoning steps in a numbered list.\n\n\n\n\nWhy does this work?"
  },
  {
    "objectID": "slides/template.html#decomposition-techniques",
    "href": "slides/template.html#decomposition-techniques",
    "title": "Presentation Template",
    "section": "Decomposition techniques",
    "text": "Decomposition techniques\n\nExplanation: Force the LLM to break down complex tasks into manageable subtasks.\nLeast-to-Most Prompting: Start simple, increase complexity.\n\nExample: List items, calculate cost…\n\nPlan-and-Solve Prompting: Separate planning and execution phases.\n\nExample: Understand the problem, devise a plan…"
  },
  {
    "objectID": "slides/template.html#hands-on-practice-prompting",
    "href": "slides/template.html#hands-on-practice-prompting",
    "title": "Presentation Template",
    "section": "Hands-on practice: Prompting",
    "text": "Hands-on practice: Prompting\n\n\nPractice writing prompts for different tasks ( 20 minutes).\nWrite an essay using an LLM, and then critique someone else’s essay ( 30 minutes).\n\n  If you need further help with prompting techniques, see these websites:\n\n Learn prompting\n Prompting guide\n OpenAI cookbook"
  },
  {
    "objectID": "slides/template.html#chatgpt-edu",
    "href": "slides/template.html#chatgpt-edu",
    "title": "Presentation Template",
    "section": "ChatGPT Edu",
    "text": "ChatGPT Edu\n\n\n \n\n\n\n\nAccess to GPT-4o, excelling in text interpretation, coding, and mathematics\nData analytics, web browsing, and document summarization\nBuild GPTs, custom versions of ChatGPT, and share them within university workspaces\nSignificantly higher message limits than the free version of ChatGPT\nImproved language capabilities across quality and speed, with over 50 languages supported\nRobust security, data privacy, and administrative controls\nConversations and data are not used to train OpenAI models"
  },
  {
    "objectID": "slides/template.html#gpts",
    "href": "slides/template.html#gpts",
    "title": "Presentation Template",
    "section": "GPTs",
    "text": "GPTs"
  },
  {
    "objectID": "slides/template.html#hands-on-practice-gpts",
    "href": "slides/template.html#hands-on-practice-gpts",
    "title": "Presentation Template",
    "section": "Hands-on practice: GPTs",
    "text": "Hands-on practice: GPTs\n\nTry out custom GPTs from various categories in the GPT store.\nDiscuss with your neighbour\n\nDid you discover any useful GPTs?\nWhat are the benefits and limitations of using GPTs in the classroom?"
  },
  {
    "objectID": "slides/template.html#extended-cognition",
    "href": "slides/template.html#extended-cognition",
    "title": "Presentation Template",
    "section": "Extended cognition",
    "text": "Extended cognition\n\n\n\nAccording to Clark and Chalmers (1998), cognitive processes may extend to external objects.\nKrakauer (2016) distinguishes between complementary and competitive cognitive artifacts.\n\nComplementary: numbers, abacus\nCompetetive: calculator, GPS\n\nWhat kind of artefact will AI turn out to be?"
  },
  {
    "objectID": "slides/template.html#deskilling-vs.-upskilling",
    "href": "slides/template.html#deskilling-vs.-upskilling",
    "title": "Presentation Template",
    "section": "Deskilling vs. upskilling",
    "text": "Deskilling vs. upskilling"
  },
  {
    "objectID": "slides/template.html#writing-tasks-in-the-ai-era",
    "href": "slides/template.html#writing-tasks-in-the-ai-era",
    "title": "Presentation Template",
    "section": "Writing tasks in the AI era",
    "text": "Writing tasks in the AI era\n\nWriting is a core skill: critical thinking, persuasion, argumentation, understanding.\nText creation is secondary in learning: focus is on underlying skills.\nLearning objectives: Benefits of writing tasks should be clearly and convincingly conveyed.\nStudents should be equipped for effective (controlled) use of AI."
  },
  {
    "objectID": "slides/template.html#ai-can-do-my-homework",
    "href": "slides/template.html#ai-can-do-my-homework",
    "title": "Presentation Template",
    "section": "AI can do my homework",
    "text": "AI can do my homework\n\nWe can think of this as cheating.\nMore useful: cheating means bypassing useful cognition and therefore missing out on learning.\nCheating an ethics problem.\nBypassing cognition is a learning problem.\nNot a new problem: books, encyclopedias, calculators, spell checkers, etc."
  },
  {
    "objectID": "slides/template.html#controlled-use-of-llms",
    "href": "slides/template.html#controlled-use-of-llms",
    "title": "Presentation Template",
    "section": "Controlled use of LLMs",
    "text": "Controlled use of LLMs\n\n\n\n\n\n\n\nTask Category\nSpecific Tasks\n\n\n\n\nEditing tasks\nCreate/improve different versions of sections.\n\n\nTransitions\nWrite and compare transitions.\n\n\nImprove drafts\nCritique and refine drafts.\n\n\nWriting styles\nRewrite sections for different audiences.\n\n\nControversial statements\nIdentify controversial points and strengthen arguments.\n\n\nResearch journal\nKeep a diary and use LLM for reflection."
  },
  {
    "objectID": "slides/template.html#sport-vs.-writing",
    "href": "slides/template.html#sport-vs.-writing",
    "title": "Presentation Template",
    "section": "Sport vs. writing",
    "text": "Sport vs. writing\n\n\n\nTechnological advancements in sports: a useful analogy for learning?\nDistinction between training and competition.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLZR Racer swim suit\nAI-base writing tools\n\n\n\n\nImprovement\nReduced Resistance, Increased Buoyancy\nImproved Grammar, Formulation, Content Creation\n\n\nFairness\nProvided an Unfair Advantage, Led to Record Performances\nConsidered Unfair in Academic Contexts\n\n\nImpact\nBanned to Maintain Competitive Integrity\nRaises Questions of Originality and Skill Development"
  },
  {
    "objectID": "slides/template.html#understanding-the-value-of-effort",
    "href": "slides/template.html#understanding-the-value-of-effort",
    "title": "Presentation Template",
    "section": "Understanding the value of effort",
    "text": "Understanding the value of effort\n\nCheating can be a symptom that learners do not understand or value the importance of their own work.\nJust like in sport: if we take shortcuts during training, we won’t get fit.\nUnderstanding the purpose is important to endure discomfort.\nLearners need to understand what they are supposed to learn, why it is valuable, and why effort and discomfort are necessary."
  },
  {
    "objectID": "slides/template.html#fraud-triangle",
    "href": "slides/template.html#fraud-triangle",
    "title": "Presentation Template",
    "section": "Fraud triangle",
    "text": "Fraud triangle"
  },
  {
    "objectID": "slides/template.html#learning-environments-that-promote-cheating",
    "href": "slides/template.html#learning-environments-that-promote-cheating",
    "title": "Presentation Template",
    "section": "Learning Environments that promote cheating",
    "text": "Learning Environments that promote cheating\n\n\n\n\n\n\n\nFactors\nDescriptions\n\n\n\n\nHigh pressure\nHigh stakes increase cheating. Fear of failure reinforces this.\n\n\nLack of intrinsic motivation\nEngagement and relevance are important. Lacking these makes cheating more attractive.\n\n\nPerceived injustice\nUnfair grading leads to cheating.\n\n\nLow fear of getting caught\nLow risk encourages cheating.\n\n\nPeer influence\nWidespread cheating among peers pressures students to join in.\n\n\nLow self-efficacy\nDoubts about one’s own abilities increase cheating as the seemingly only option."
  },
  {
    "objectID": "slides/template.html#strategies-to-reduce-cheating",
    "href": "slides/template.html#strategies-to-reduce-cheating",
    "title": "Presentation Template",
    "section": "Strategies to Reduce Cheating",
    "text": "Strategies to Reduce Cheating\n\n\n\n\n\n\n\nStrategies\nDescriptions\n\n\n\n\nFoster intrinsic motivation\nSpark genuine interest. Provide choices and practical applications.\n\n\nMastery learning\nClear learning objectives. Focus on mastery of content. Include constructive and corrective feedback in formative assessments.\n\n\nReduce pressure\nDiversify assessment methods. Use portfolios and low-stress tests to reduce anxiety.\n\n\nStrengthen self-efficacy\nProvide constructive feedback and promote peer learning (peer tutoring, peer review).\n\n\nCreate a culture of integrity\nOpen discussion about academic integrity. Set clear guidelines and promote community ethics."
  },
  {
    "objectID": "slides/template.html#academic-integrity-plagiarism",
    "href": "slides/template.html#academic-integrity-plagiarism",
    "title": "Presentation Template",
    "section": "Academic Integrity: Plagiarism",
    "text": "Academic Integrity: Plagiarism\n\n\n\n\n\n\n\nTypes of Plagiarism\nDescription\n\n\n\n\nUnattributed use\nUsing the work or ideas of others without proper attribution.\n\n\nMinor changes or translations\nUsing the work of others with minor changes or translations without attribution.\n\n\nSelf-plagiarism\nReusing substantial parts of one’s own work without proper citation.\n\n\nJoint works\nReusing jointly written publications without proper acknowledgment."
  },
  {
    "objectID": "slides/template.html#academic-integrity-misconduct-in-authorship",
    "href": "slides/template.html#academic-integrity-misconduct-in-authorship",
    "title": "Presentation Template",
    "section": "Academic Integrity: Misconduct in authorship",
    "text": "Academic Integrity: Misconduct in authorship\n\n\n\n\n\n\n\nTypes of Plagiarism\nDescription\n\n\n\n\nUnattributed use\nUsing the work or ideas of others without proper attribution.\n\n\nMinor changes or translations\nUsing the work of others with minor changes or translations without attribution.\n\n\nSelf-plagiarism\nReusing substantial parts of one’s own work without proper citation.\n\n\nJoint works\nReusing jointly written publications without proper acknowledgment."
  },
  {
    "objectID": "slides/template.html#how-to-cite-chatgpt",
    "href": "slides/template.html#how-to-cite-chatgpt",
    "title": "Presentation Template",
    "section": "How to cite ChatGPT",
    "text": "How to cite ChatGPT\nE.g. APA Style: Cite as software (not as personal communication)."
  },
  {
    "objectID": "slides/template.html#documentating-ai-use",
    "href": "slides/template.html#documentating-ai-use",
    "title": "Presentation Template",
    "section": "Documentating AI use",
    "text": "Documentating AI use\n\nSpecifying prompts works well for inexperienced users, but inadequately reflects complex processes.\nExperienced users work with dialogues and several tools, not monolithic prompts in ChatGPT.\nWorking with copilot (code): no traceable prompt input.\nInstead: Document the process, including the tools used and the steps taken.\n\nInclude used tools and steps in appendix, with optional graphical representation.\nServes both evaluation and self-reflection.\n\nIs documentation meaningful in the long term, once the use of AI-based tools has become commonplace?"
  },
  {
    "objectID": "slides/template.html#detecting-ai-use",
    "href": "slides/template.html#detecting-ai-use",
    "title": "Presentation Template",
    "section": "Detecting AI use",
    "text": "Detecting AI use\n\nCan be detected by the use of specific vocabulary and phrases: “delve”, “vibrant”, “embark”, “it’s important to note”, ” based on the data provided”.\nDetection tools are not very useful, and can be easily circumvented.\nAccording to Fleckenstein et al. (2024)\n\nGenerative AI can write papers that are undetectable.\nTeachers overestimate their detection abilities."
  },
  {
    "objectID": "pages/index.html#ki-in-der-lehre-intermediate",
    "href": "pages/index.html#ki-in-der-lehre-intermediate",
    "title": "Virtuelle Akademie",
    "section": "",
    "text": "[ bfh.ch/de/weiterbildung/kurse/ki-in-der-lehre-intermediate/"
  },
  {
    "objectID": "pages/index.html#contents",
    "href": "pages/index.html#contents",
    "title": "Virtuelle Akademie",
    "section": "",
    "text": "Using language models in teaching: Explore how language models can be effectively integrated into teaching and learning strategies.\nPractical exercises and experiments with prompting LLMs to optimize the use of AI tools in teaching.\nDiscussion and exchange: Discuss challenges and best practices in using AI in teaching with other participants.\nDevelop your own use cases and scenarios for using AI in your teaching."
  }
]